## Entendimento de Negócios

### Analise do parceiro de projeto

A Samba Tech é uma empresa líder em soluções de vídeo online na América Latina. Fundada por Gustavo Caetano, a empresa começou suas operações focando inicialmente em soluções de entretenimento e jogos para celulares, mas ao longo do tempo, pivoteou seu modelo de negócios para se concentrar em soluções de vídeo online devido à crescente demanda por conteúdo digital e à evolução da tecnologia de streaming.

A Samba Tech se especializou em fornecer uma plataforma robusta para hospedagem, transmissão e gestão de vídeos online, atendendo a uma ampla gama de clientes, incluindo empresas de mídia, marcas, instituições de ensino e criadores de conteúdo. Suas soluções permitem que os usuários gerenciem, distribuam e monetizem seus conteúdos de vídeo de forma eficiente e segura, oferecendo recursos como análise de dados, personalização de players de vídeo, proteção de conteúdo, e integração com diversas plataformas e dispositivos.

Um dos diferenciais da Samba Tech é a sua capacidade de oferecer soluções personalizadas de acordo com as necessidades específicas de cada cliente, além de fornecer suporte técnico e consultoria para ajudar as empresas a maximizar o impacto de suas estratégias de vídeo online. A empresa também se destaca por sua inovação contínua, buscando sempre implementar as últimas tecnologias e tendências do mercado digital para aprimorar suas soluções e serviços.

## Analise SWOT

É crucial que a empresa continue a inovar e adaptar-se às mudanças do mercado para manter sua posição de liderança e explorar novas oportunidades de crescimento. Para entender melhor sobre o negócio em que a empresa atual criamos uma análise SWOT que oferece uma visão geral das principais forças, fraquezas, oportunidades e ameaças que a Samba Tech pode enfrentar.

![Grupo Sorriso Maroto - SWOT Analysis](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110571286/ea640394-e781-420f-a7b2-f198aadd4e14)

Figura x: Análise SWOT SambaTech

## Matriz Oceano Azul

No contexto competitivo atual, as empresas estão constantemente buscando inovar e diferenciar-se para explorar novos mercados. A matriz de oceano azul serve como uma ferramenta estratégica crucial nesse processo, permitindo às organizações repensar e remodelar suas ofertas de produtos ou serviços. O nosso projeto se alinha com essa visão, propondo uma abordagem inovadora para análise e interação com conteúdos em vídeo. Vamos explorar como nosso projeto se encaixa em cada um dos quatro pilares da matriz de oceano azul:

![Grupo Sorriso Maroto - Blue Ocean](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110571286/a588ba92-eef7-4d37-80dc-fbfc82e8e1af)

Figura x: Matriz Oceano Azul

**Elimina:** O projeto propõe a eliminação de análises de dados via relatórios estáticos ou planilhas e processos manuais de coleta e preparação de dados. Ao adotar tecnologias avançadas de processamento de linguagem natural (NLP) e inteligência artificial, miramos na automatização desses processos, facilitando a obtenção de insights mais profundos e relevantes de forma eficiente e dinâmica através de um dashboard completo.

**Reduz:** Nossa solução visa reduzir significativamente o tempo necessário para gerar insights valiosos, simplificando o processo de busca e análise de vídeos. Além disso, buscamos diminuir a complexidade e o tempo requerido para a tomada de decisões, tornando esses processos mais ágeis e fundamentados em dados de alta qualidade e relevância.

**Aumenta:** O projeto foca em aumentar a qualidade da entrega de conteúdos por parte dos contratantes aos seus usuários, assim como o entendimento das preferências desses usuários. Com a implementação de nossa solução, as plataformas, como o serviço Samba Vídeos, poderão oferecer conteúdos mais alinhados com os interesses e necessidades de seu público, potencializando a satisfação e engajamento dos usuários entendendo mais sobre o que e melhor aceito no mercado.

**Cria:** Por fim, nosso projeto cria novas possibilidades de interação e análise de conteúdo. Encontrar padrões de sucesso através de NLP permitirá às empresas cliente compreender melhor o que faz um conteúdo ser bem-sucedido, enquanto a interação do usuário por áudio através de uma nova feature de pesquisa por voz oferecerá uma experiência mais rica e acessível, abrindo portas para uma nova forma de consumir e interagir com conteúdos em vídeo.

Nosso projeto não só aborda desafios existentes no mercado, mas também propõe soluções inovadoras que alavancam tecnologias de ponta para criar um novo espaço de mercado. Ao fazer isso, esperamos não apenas atender às necessidades atuais dos nossos clientes, mas também antecipar e moldar futuras demandas, navegando com sucesso nas águas azuis de oportunidades inexploradas.

Ao considerar todos esses aspectos fica claro na matriz de avaliação de valor abaixo, que nosso projeto não apenas se destaca por sua capacidade de inovar e agregar valor, mas também por sua abordagem estratégica em equilibrar custos e benefícios.

![Matriz de avaliação de valor](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110571286/cb5cf110-127f-4284-b1b0-4e754e8bbfb1)

Figura x: Matriz de avaliação de valor

## Canvas Proposta de Valor

No mercado de transmissão e distribuição de vídeos pela internet, plataformas enfrentam desafios constantes para atender e superar as expectativas dos clientes. Neste cenário, nosso projeto visa oferecer uma solução inovadora que aborda diretamente as necessidades críticas e desafios enfrentados pelas plataformas e seus usuários. Através do nosso assistente de análise de dados, que utiliza tecnologias avançadas de processamento de linguagem natural (NLP) em vídeos, e a introdução de novas métricas de avaliação, propomos uma abordagem revolucionária para compreender e engajar o público de forma mais eficaz. Podemos entender melhor sobre como isso beneficia a empresa através do nosso Value Proposition Canvas abaixo:

![Grupo Sorriso Maroto - Value Proposition Canva (5)](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110571286/1c5465b6-0400-4a3b-8a95-4662eb2a992d)

Figura x: Canvas Proposta de Valor - VPC

**Customer Jobs:** A plataforma de transmissão e distribuição de vídeos buscam constantemente melhorar a entrega de conteúdo relevante e engajante, otimizar a experiência do usuário e maximizar a retenção e o engajamento. A complexidade de gerenciar grandes volumes de conteúdo e compreender as preferências dos usuários representa um desafio significativo..

**Pains:** Nossos clientes enfrentam dificuldades em entender as expectativas dos usuários, lidam com processos manuais e demorados, encontram limitações na análise do conteúdo dos vídeos, sofrem com a falta de personalização e dispõem de poucas métricas para avaliar o comportamento dos usuários. Esses desafios dificultam a criação de insights valiosos e a tomada de decisões estratégicas.

**Pain Relievers:** Nosso assistente de análise de dados e as novas métricas de avaliação aliviam essas dores oferecendo uma análise eficiente de grandes conjuntos de dados, permitindo uma compreensão profunda do comportamento dos usuários e facilitando a visualização dos dados gerados pela plataforma. Essas soluções reduzem a dependência de processos manuais e melhoram a capacidade das plataformas de personalizar e otimizar o conteúdo para seus usuários.

**Gains:** Ao implementar nosso projeto, as plataformas podem esperar entender melhor a preferência de conteúdo dos usuários, ganhar uma vantagem estratégica por meio de estatísticas aprofundadas, aumentar a retenção e o engajamento dos usuários, melhorar o entendimento dos dados gerados pela plataforma e alcançar maior eficiência na tomada de decisões.

**Gain Creators:** A criação de valor é amplificada por um dashboard intuitivo que apresenta insights gerados a partir dos dados, análise de sentimentos, análise da linguagem nos vídeos, extração de tópicos relevantes, análise da interação dos usuários com os vídeos e a identificação de padrões de sucesso. Essas funcionalidades não só ajudam a mapear as preferências dos usuários de maneira mais precisa, mas também proporcionam às plataformas as ferramentas necessárias para adaptar estrategicamente seu conteúdo e serviços.

## Matriz de Riscos

A matriz de riscos é uma ferramenta de gerenciamento usada para identificar, avaliar e priorizar os riscos potenciais em um projeto, processo ou sistema. É uma parte essencial do processo de gerenciamento de riscos, ajudando as equipes a tomar decisões informadas e a implementar medidas preventivas ou de contingência para mitigar os impactos negativos dos riscos identificados. Para o projeto, foram definidos 10 possíevis riscos, que podem ser visualizados na matriz a seguir:

![riscos](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/88b0136f-e91c-4dcb-998a-c0490e243c19)

Figura x: Matriz de Riscos

**A - Tecnologia:**

Risco: Possíveis falhas na análise de dados ou identificação de conteúdo.

Mitigação: Implementação de algoritmos robustos, testes frequentes e atualizações contínuas.

**B - Privacidade:**

Risco: Questões relacionadas à privacidade dos usuários devido à análise de dados.

Mitigação: Estrita conformidade com regulamentações de privacidade, transparência nas políticas e opções de consentimento claro.

**C - Conteúdo Inadequado:**

Risco: Identificação incorreta de conteúdo, resultando em exibição inadequada de anúncios.

Mitigação: Revisões manuais regulares, feedback da comunidade e aprimoramento constante dos algoritmos de análise.

**D - Segurança:**

Risco: Vulnerabilidades de segurança que podem comprometer dados sensíveis.

Mitigação: Investimento em medidas de segurança cibernética, criptografia robusta e auditorias regulares.

**E - Parcerias Comerciais:**

Risco: Desafios na obtenção de parcerias devido a preocupações com análise de dados e direcionamento de anúncios.

Mitigação: Comunicação transparente sobre práticas de dados e potenciais benefícios para parceiros comerciais.
Claro, aqui estão os pontos de ameaça refatorados com os riscos associados e as estratégias de mitigação:

**F - Concorrência de Grandes Players:**

Risco: Entrada de grandes empresas de tecnologia no mercado, oferecendo soluções similares ou superiores a preços competitivos.

Mitigação: Investir em diferenciação por meio de recursos exclusivos, focar em nichos de mercado específicos, oferecer um excelente suporte ao cliente e estabelecer parcerias estratégicas.

**G -Problemas de Escalabilidade:**

Risco: Incapacidade de dimensionar a infraestrutura para lidar com um aumento repentino no número de usuários ou volume de transcrições.

Mitigação: Realizar testes de carga frequentes, utilizar serviços de nuvem escaláveis, monitorar de perto os indicadores de desempenho e investir em infraestrutura redundante e resiliente.

**H - Falhas de Integração com Plataformas de Vídeo:**

Risco: Problemas na integração com diferentes plataformas de vídeo, levando a inconsistências na transcrição ou perda de funcionalidades.

Mitigação: Realizar testes extensivos de integração, manter-se atualizado com as APIs das plataformas de vídeo, estabelecer parcerias com os fornecedores de plataforma e manter uma equipe de suporte técnico dedicada.

**I - Rejeição por Usuários devido à Precisão das Transcrições:**

Risco: Baixa precisão das transcrições automáticas, resultando em insatisfação dos usuários e perda de confiança na plataforma.

Mitigação: Investir em algoritmos de transcrição avançados, implementar sistemas de revisão manual, oferecer opções de edição de transcrição pelos usuários e solicitar feedback regular para melhorias contínuas.

**J - Regulamentações em Evolução:**

Risco: Mudanças frequentes nas regulamentações relacionadas à privacidade, acessibilidade e direitos autorais, aumentando a complexidade e os custos operacionais da plataforma.

Mitigação: Manter-se atualizado com as leis e regulamentos relevantes, investir em conformidade desde o início do desenvolvimento da plataforma, colaborar com especialistas legais e participar de grupos de trabalho do setor para antecipar e se adaptar às mudanças regulatórias.

## Análise Financeira

DETALHAMENTO DOS CUSTOS DO PROJETO

Os valores apresentados estão em Reais (R$), com a cotação do dólar americano considerada para a conversão de custos originalmente estimados em dólares, sendo esta cotação de R$ 4,97.

#### Custos Mensais de Serviços de Tecnologia

Os custos mensais referentes aos serviços de tecnologia, necessários para a implementação e operacionalização do projeto, são discriminados a seguir:

  - Serviços AWS (Amazon Web Services):
  - AWS RDS: R$ 2.236,50
  - AWS S3: R$ 118,44
  - 2 EC2 t4g.medium (com 2 CPU e 4GiB de memória cada): R$ 121,12
  - 1 EC2 r6gd.large (com 2 CPU e 16GiB de memória): R$ 216,27
  - Watson Assistant (IBM): R$ 695,80
**Total de Custos Mensais de Serviços de Tecnologia:** R$ 3.388,10

#### Custos com Equipe
Os custos associados à equipe envolvida no desenvolvimento e manutenção do projeto são apresentados a seguir:

  - 4 Desenvolvedores de Software Junior: R$ 16.000,00 (R$ 4.000,00 por desenvolvedor, totalizando um período de 10 semanas de trabalho)
  - 1 Analista de Dados: R$ 6.000,00 mensais
  - 1 Desenvolvedor Pleno: R$ 7.000,00 mensais
**Total de Custos Mensais com Equipe:** R$ 29.000,00

#### Custos Totais do Projeto
Com base nos custos mensais detalhados, o custo total mensal do projeto é de R$ 32.388,10. Para o período inicial de 10 semanas (aproximadamente 2,5 meses), o custo total estimado do projeto é de R$ 80.970,25.

**Observações**
  - Os custos com os Desenvolvedores de Software Junior são considerados para o período inicial de 10 semanas, sendo posteriormente ajustados conforme a necessidade do projeto.
  - Quaisquer alterações nos custos projetados serão comunicadas e documentadas.

Para obter detalhes precisos sobre a capacidade de armazenamento e memória das instâncias EC2, do serviço RDS e do armazenamento S3, consulte as especificações técnicas disponíveis [clicando aqui](https://drive.google.com/file/d/1DJawACjpC5otAuBdRnNicZ7SDrcL7Sv0/view?usp=sharing) para ter acesso ao PDF com as informações, originadas do AWS Calculator.


#### Lucros

**Receita de anúncios:** Com a aplicação de propagandas mais assertivas, é possível atrair anunciantes interessados em alcançar um público específico. A receita virá das parcerias de publicidade e da exibição dos anúncios nos vídeos. Diversas empresas já oferecem o serviço de divulgação, então já temos um preço base no qual podemos usar como base.

**Assinaturas premium:** Pode ser oferecido uma versão premium da plataforma com recursos adicionais ou sem anúncios, cobrando uma taxa mensal ou anual dos usuários que optarem por essa opção. Diversas plataformas já disponibilizam serviços de assinaturas para não ter propagandas, como o forte da plataforma são os anúncios assertivos, devemos cobrar uma taxa respectiva para compensar o custo, porém não pode ser alta pois deixa de ser competitiva. Levando todos os requisitos acima, podemos cobrar uma taxa de R$ 35 a R$50 por mês.

## Entendimento do Design

### Estudo sobre o usuário do sistema

No contexto da aplicação, para entender-se quais personas estão relacionadas a solução, primeiro, deve-se ter uma pequena introdução sobre seu contexto. Sendo assim, o principal stakeholder em contato com o time é a empresa Samba Tech que por meio de sua plataforma, Samba Vídeos, oferece uma solução para armazenar e disponibilizar conteúdos em vídeo para outras empresas. Seus clientes são diversificados, portanto, o recorte desse MVP serão as instituições educacionais de ensino superior que oferecem cursos por EAD.

Dessa forma, o sistema impacta direta ou indiretamente três usuários, sendo eles:
Aluno, será impactado indiretamente pelo sistema;
Diretora Acadêmica / Cliente, utilizará o sistema;
Diretores do Samba Vídeo, serão impactados indiretamente em um primeiro momento, mas é possível que se tornem usuários da plataforma;

O aluno, cliente da instituição de ensino, pode ter os mais diversos perfis e habilidades. Sendo assim, escolhemos como persona um estudante EAD de engenharia de software que trabalha como vendedor em um shopping. Seu contexto envolve um jovem que já vem de uma geração acostumada com as novas formas de tecnologia, porém, ainda não tem conhecimento de engenharia de software e programação. Contudo, será impactado indiretamente pelo sistema devido a receber uma melhor oferta de conteúdos baseados nas análises que a solução proporciona.

![rSNpJzDl1Y_a5-ZyareTAhYMvGX5fdwKKckGjGWrCgOOMZrc980j0I8tqze1GRwRDZbxTXEV6bDD3Ny6bm1wIZBcbU5CNzElt2eNy2xhFB3k_pQlBwT3tIx_5Z4EgfFRMc5iVm0qSFR0UfkrPIP4W9E](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/c51f1161-93b3-4609-8163-8786fcd1cd34)

Figura x: Dados persona João Silva

A Diretora Acadêmica representa o papel de cliente da Samba Vídeos. Essa posição foi escolhida devido à preocupação com a curadoria e técnicas que envolvem o conteúdo de aulas de uma instituição, além de estar relacionada à temática do recorte de mercado escolhido. Seu contexto envolve uma mulher de 50 anos, mestra em pedagogia e, realmente, a usuária do dashboard solução. Como responsável geral da qualidade dos cursos ofertados, a solução proposta consegue trazer clareza e agilidade na análise dos conteúdos fornecidos e gerar insights de melhoria, agregando valor e possivelmente alavancando posições nesse mercado tão concorrido.

![rz5mdGSskpLHbNkor6RBc25kD1mfkhJWZGpvna9PFWVqUG4gh2LljDJ3hv_wSr--aKo3kFRwZTkk58bMNXYFD5Pav9Ho4IjebvVihhV693qwZBgtFUlYU071WE19cCNvr3-AdruK0HQ47_6dkDCF8y0](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/447f8c7d-ee99-4d7d-ae71-ab3a8fcae887)

Figura x: Dados persona Fabricia Lara

O Diretor de Conteúdos chama-se Renato Gomes, cargo fictício que condensa a responsabilidade de captação de clientes e growth, para trazer valor para o serviço que o Samba Vídeos presta. Será afetado pelo sistema indiretamente até a entrega da solução como MVP devido à facilidade de gerar relatórios aos seus clientes (visto que antes possivelmente era necessária a criação de um chamado para sua equipe). Ainda sim, a solução tem potencial para receber um acesso ao nível geral, podendo acessar como estão as métricas gerais de conteúdo, por área ou por empresa.

![yLQu-PEghRnC7puNKwU1Ik6dbwvzjNov_wLozNCvFMLwpw-m3IhR3iVB03qDTPjGAZR5bgszflpc_CPeyTYk7jVAV6EtTSeO5iszJ5QFH3-t9gcRsEDCwyiEekqWrNC0XS5ZvvK-KHE6uKbTm1lTaNI](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/08ea22c8-b40d-4cc9-9c62-eb17e3fa1135)

Figura x: Dados persona Renato Gomes

### Experiências que o usuário deverá passar ao utilizar o sistema

Ao utilizar a proposta de solução, os usuários poderão vivenciar uma série de experiências que contribuam para uma interação fluida, agradável e eficiente. Uma opção para esse ínicio de projeto, é a jornada a seguir:

1. **Primeira Interação e Onboarding:**
   - O usuário é recebido com uma interface intuitiva e amigável, apresentando uma breve introdução sobre os recursos e funcionalidades principais do sistema.
   - Durante o onboarding, é guiado através dos elementos da interface, como o componente de busca textual ou por áudio, os diferentes insights disponíveis e como acessá-los.

2. **Exploração dos Insights:**
   - Ao acessar o dashboard, o usuário encontra os diferentes componentes de insights disponíveis de forma clara e organizada.
   - Ele pode explorar os trending topics, visualizando os conteúdos mais vistos em uma tabela de fácil compreensão e identificação.
   - Ao analisar o gráfico de minutos x visualizações, o usuário compreende de forma rápida e visual o tempo ideal de vídeo em relação ao número de visualizações.
   - Na seção de métricas de comunicação, o usuário pode avaliar diversos aspectos da comunicação nos vídeos, interpretando os valores apresentados em uma escala de 0 a 10.

3. **Interatividade e Facilidade de Uso:**
   - O usuário experimenta a facilidade de interação com o sistema, seja através da busca textual ou por áudio, encontrando informações de forma rápida e precisa.
   - Ao realizar uma busca, o sistema interpreta a intenção do usuário e apresenta os resultados de maneira clara e objetiva, utilizando gráficos, tabelas ou outros elementos visuais pré-programados.

4. **Personalização e Adaptação:**
   - O sistema permite que o usuário personalize sua experiência, modificando e substituindo os componentes de insights de acordo com suas necessidades e preferências.
   - Ele pode ajustar os filtros e parâmetros das métricas de comunicação para obter análises mais específicas e relevantes para seu contexto.

5. **Feedback e Aprendizado Contínuo:**
   - Durante a interação com o sistema, o usuário recebe feedback imediato sobre suas ações, facilitando o entendimento e a utilização das funcionalidades.
   - O sistema aprende com as interações do usuário, adaptando-se gradualmente às suas preferências e fornecendo sugestões e recomendações relevantes.

Ao proporcionar essas experiências, o sistema busca garantir uma jornada de usuário fluida, agradável e eficiente, antecipando suas necessidades e fornecendo soluções adequadas para a análise e interpretação de dados relacionados aos vídeos educacionais.

### Proposta de UX

Baseado no estudo do contexto da indústria, pessoas impactadas pelo sistema e a experiência que desejamos transmitir, foi desenvolvida uma proposta de interface de dashboard para a solução. Sua principal característica é a facilidade de entendimento das informações, transmitindo claramente os insights coletados no projeto. Além da facilidade de entendimento, outra característica é a facilidade de uso. Para tal, há um componente que busca a interação do usuário de forma simplificada mediante uma busca textual ou por áudio. O input gerado por essa busca será convertida em uma intenção e então o componente transforma-se em um gráfico, tabela ou outro elemento visual pré-programado que responde ao pedido. Contudo, em sua primeira versão, visamos desenvolver a interface inspirada no design system da Samba Tech, porém sem o compromisso de seguir todas as regras para abrirmos espaço para diferentes ideias. Os componentes de insights pensados, permitindo modificações e substituições ao decorrer do projeto, foram:

- **Trending Topics**: Tópicos extraídos do conteúdo falado do vídeo metrificado por visualizações, trazendo os conteúdos mais vistos. Apresentado por meio de uma tabela em ordem decrescente de visualizações;
- **Minutos X Visualizações**: Tempo ideal de vídeo metrificado por meio de tempo total por visualizações. Apresentado por meio de um gráfico de barras;
- **Métricas de Comunicação**: Diversas métricas relacionadas a como ocorre a comunicação pelo vídeo metrificado por visualizações, sendo cada item retirado da transcrição do vídeo. Seus subtópicos são apresentados por meio de um range de 0 a 10, podendo 0 significar algo como "informalidade", por exemplo:
  - **Interação**: Perguntas ao ouvinte;
  - **Formalidade**: O quão formal é a comunicação;
  - **Exemplos**: Se os conceitos passados são exemplificado;
  - **Metáforas**: Se metáforas são usadas como forma de ensino;
- **Busca**: Componente onde o usuário pode buscar por texto ou audio outra informação que pode ser apresentada de diversas maneiras;

![Dashboard](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/ce24a58c-f7c5-4625-8e9d-2ece363b0493)

### Pilha de Tecnologias

O sucesso do nosso projeto inovador de análise de dados em vídeos e pesquisa por voz em plataformas de distribuição de vídeos pela internet é sustentado pela adoção de uma série de tecnologias avançadas e ferramentas de desenvolvimento apropriadas para este tipo de projeto. Cada uma dessas tecnologias foi cuidadosamente selecionada para garantir que nosso sistema seja robusto, escalável, e capaz de atender às necessidades complexas de análise de dados e interação do usuário de maneira eficiente. A seguir, detalhamos as tecnologias fundamentais que formam a base do nosso projeto:

<br>

<img src="../docs/img/pilhatech1.png" alt="Texto Alternativo">
<img src="../docs/img/pilhatech2.png" alt="Texto Alternativo">

<br>

### Descrição detalhada:

- **React:** React é uma biblioteca JavaScript de código aberto utilizada para construir interfaces de usuário (UI). Desenvolvida e mantida pelo Facebook, o React permite a criação de componentes reutilizáveis que gerenciam seu próprio estado. Ele utiliza uma abordagem declarativa para a criação de interfaces, tornando mais fácil compreender e depurar o código. React será a biblioteca principal para o desenvolvimento do frontend.
- **Typescript:** TypeScript é uma linguagem de progrmação superset do JavaScript que adiciona tipagem estática ao código JavaScript. Ele ajuda a detectar erros de código em tempo de desenvolvimento, tornando-o mais robusto. TypeScript é a linguagem principal para o desenvolvimento do backend e frontend.

- **Tailwind CSS:** Tailwind CSS é uma biblioteca de utilitários CSS altamente configurável e de baixo nível. Permite a construção eficiente de interfaces de usuário, fornecendo classes CSS pré-definidas que podem ser aplicadas diretamente no HTML. É conhecido por sua abordagem utility-first, facilitando a criação de designs flexíveis e responsivos. Tailwind CSS será a biblioteca de utilitários CSS utilizada para estilizar a interface de usuário de forma eficiente.

- **Visual Studio Code:** Visual Studio Code (VSCode) é um editor de código-fonte leve, poderoso e altamente personalizável desenvolvido pela Microsoft. É amplamente utilizado por desenvolvedores para uma variedade de linguagens de programação. Oferece suporte a extensões, depuração integrada, controle de versão e uma ampla gama de recursos que melhoram a produtividade do desenvolvedor. Visual Studio Code será o editor de código principal, oferecendo uma interface amigável e altamente personalizável.

- **Vite:** Vite é uma estrutura de desenvolvimento para React ou Vue, um framework JavaScript progressivo para a construção de interfaces de usuário. Vite foca em proporcionar uma experiência de desenvolvimento rápida, suportando carregamento de módulos ES com eficiência e facilitando o desenvolvimento de aplicativos Vue.js modernos e eficientes. Vite será utilizado para agilizar o desenvolvimento do frontend React.

- **Node.js:** Node.js é um ambiente de tempo de execução JavaScript que permite executar código JavaScript no lado do servidor. É amplamente utilizado para construir aplicativos da web escaláveis e em tempo real. Node.js será a base do backend, permitindo a execução eficiente de código JavaScript no lado do servidor.

- **AWS EC2 (Elastic Compute Cloud):** EC2 é um serviço da AWS que fornece capacidade de computação escalável na nuvem.
  É frequentemente utilizado para hospedar aplicativos web, servidores, e outros recursos computacionais.
  É possível configurar instâncias EC2 para executar servidores Node.js, React e outros ambientes. EC2 será utilizado para hospedar instâncias de servidores Node.js e React.

- **AWS RDS:** RDS é um serviço de banco de dados gerenciado pela AWS que suporta vários motores de banco de dados relacionais. Pode ser usado para hospedar bancos de dados MySQL, PostgreSQL, SQL Server, entre outros. É uma opção eficiente para armazenar dados de aplicativos web de forma segura e escalável. RDS gerenciará bancos de dados relacionais para armazenar dados analíticos de consumo de vídeos.

- **AWS S3 (Simple Storage Service):** S3 é um serviço de armazenamento de objetos escalável e altamente durável da AWS.
  É comumente usado para armazenar e recuperar dados, como imagens, vídeos e arquivos estáticos de aplicativos web.
  É integrado facilmente com outros serviços da AWS, como EC2 e RDS. S3 armazenará grandes volumes de dados, como vídeos e conjuntos de dados para treinamento de IA.

- **Docker**: Docker é uma plataforma de contêinerização que permite empacotar, distribuir e executar aplicativos em contêineres. Contêineres fornecem uma maneira consistente e isolada de executar aplicativos, facilitando a implantação e escalabilidade. Docker simplifica a gestão de dependências e ambientes, garantindo a portabilidade entre diferentes sistemas. Docker será utilizado para empacotar as aplicações em contêineres, garantindo consistência e portabilidade.

- **IBM Watson Speech to Text**: IBM Watson Speech to Text é um serviço baseado em nuvem que converte áudio em texto de maneira automatizada e precisa. Utilizando avançadas tecnologias de reconhecimento de voz, o serviço permite a transcrição de arquivos de áudio ou streaming em tempo real. No contexto do projeto, o IBM Watson Speech to Text pode ser integrado para converter o áudio presente nos vídeos da plataforma em texto. Essa funcionalidade é essencial para analisar e compreender o conteúdo falado nos vídeos, contribuindo para a coleta de dados e treinamento de modelos de inteligência artificial.

- **RabbitMQ:** RabbitMQ é um intermediário de mensagens de código aberto que implementa o protocolo de mensagens avançado (AMQP). Desenvolvido para lidar com a comunicação assíncrona entre diferentes partes de aplicativos distribuídos, o RabbitMQ oferece uma maneira confiável e escalável de enviar, receber e processar mensagens. Sua arquitetura flexível e sua capacidade de integração com uma variedade de plataformas o tornam uma escolha popular para sistemas que exigem troca de mensagens robusta e eficiente.

- **Grafana:**  Grafana é uma plataforma de análise e visualização de dados de código aberto, projetada para ajudar a entender e monitorar sistemas complexos. Com uma ampla gama de painéis interativos e gráficos personalizáveis, o Grafana permite criar visualizações detalhadas e informativas em tempo real. Sua integração com uma variedade de fontes de dados, incluindo bancos de dados, sistemas de monitoramento e serviços em nuvem, o torna uma ferramenta poderosa para monitorar o desempenho e a integridade dos sistemas.

- **FastAPI:**  FastAPI é um framework web de alto desempenho para construir APIs com Python 3. Inspirado no Flask e no Starlette, o FastAPI combina a facilidade de uso do Python com a velocidade e a segurança do tipo de dados declarativos. Com suporte integrado para documentação automática e validação de dados, o FastAPI simplifica o desenvolvimento de APIs rápidas e escaláveis, tornando-o uma escolha popular para desenvolvedores que buscam eficiência e produtividade.

- **scikit-learn (sklearn):**  Scikit-learn é uma biblioteca de aprendizado de máquina de código aberto para Python. Projetada para ser simples e eficiente, scikit-learn oferece uma ampla variedade de algoritmos de aprendizado supervisionado e não supervisionado, bem como ferramentas para pré-processamento de dados e avaliação de modelos. Com sua interface consistente e fácil de usar, scikit-learn é amplamente adotado por cientistas de dados e desenvolvedores para tarefas de classificação, regressão, clustering e muito mais.

- **spaCy:**  spaCy é uma biblioteca de processamento de linguagem natural (PLN) de código aberto para Python. Focada em eficiência e desempenho, spaCy oferece uma ampla gama de recursos para processamento de texto, incluindo tokenização, análise morfológica, reconhecimento de entidades nomeadas e muito mais. Sua arquitetura modular e sua integração com modelos pré-treinados facilitam o desenvolvimento de aplicativos PLN sofisticados e escaláveis.

- **IBM Natural Language Understanding (NLU):**  IBM Natural Language Understanding é um serviço de PLN baseado em nuvem que extrai insights de texto de maneira automatizada e precisa. Utilizando técnicas avançadas de análise de linguagem natural, o NLU permite a identificação de entidades, sentimentos, conceitos e muito mais em documentos de texto. Sua capacidade de processar texto em vários idiomas e sua integração com outras ferramentas da IBM o tornam uma escolha popular para aplicativos que exigem compreensão semântica avançada e análise de texto.

- **GPT API:**  GPT API é uma interface de programação de aplicativos (API) baseada em modelos de linguagem de inteligência artificial, como o GPT (Generative Pre-trained Transformer). Desenvolvida pela OpenAI, a GPT API permite gerar texto coerente e contextualmente relevante em resposta a uma variedade de entradas de texto. Sua capacidade de compreender e produzir linguagem natural a torna uma ferramenta poderosa para uma variedade de aplicativos, incluindo geração de texto, tradução automática, sumarização de documentos e muito mais.


## Entendimento da Arquitetura do Sistema

### Requisitos Funcionais

#### RF1 - Obter vídeos do usuário

**Nome**: Obter vídeos do Usuário

**Descrição**: A aplicação deve ser capaz de obter os vídeos do usuário com informações como: URL ou arquivo do vídeo, quantidade de visualizações, tempo de vídeo, quantidade de comentários e avaliações.

**Ator**: Sistema

**Fluxo de eventos**:
1. O sistema inicia uma conexão ou prepara as credenciais de acesso ao repositório ou API da Samba vídeos
2. O sistema lista as informações de um ou mais vídeos do usuário
3. O sistema converte as informações para o formato especificado, caso necessário

**Pré-condições**: O sistema deve estar em correto funcionamento e através de uma rotina ou rota, consultar ou receber os vídeos da Samba Vídeos.

**Pós-condições**: O sistema deve manter-se em funcionamento e obter uma lista de vídeos da Samba Vídeos relacionados ao usuário.

#### RF2 - Gerar transcrição de vídeos da Samba Vídeos

**Nome**: Gerar transcrição de vídeos da Samba Vídeos

**Descrição**: A aplicação deve gerar transcrição do conteúdo falado nos vídeos a partir de arquivos MP4. A transcrição pode ser gerada a partir de um serviço externo ou lógica de programação interna.

**Ator**: Sistema

**Fluxo de eventos**:
1. O sistema recebe um arquivo de vídeo ou url de um arquivo mp4
2. Caso for uma url, o sistema deve baixar localmente o arquivo
3. O sistema deve converter o arquivo de vídeo para um arquivo de áudio como .flac ou .wav, caso necessário.
4. O sistema deve realizar a transcrição do conteúdo dito do vídeo acessando um serviço externo ou lógica interna.
5. O sistema deve salvar a transcrição dos vídeos


**Pré-condições**: O sistema deve estar em correto funcionamento e através de uma rotina ou rota, consultar ou receber os vídeos que precisarem de transcrição.

**Pós-condições**: O sistema deve manter-se em funcionamento e salvar a transcrição do conteúdo dito. Caso não haja transcrição, o resultado da transcrição deve ser uma string vazia.

#### RF3 - Obter Métricas de comunicação dos vídeos

**Nome**: Obter métricas de comunicação dos vídeos

**Descrição**: A aplicação deve ser capaz de através da transcrição dos vídeos, obter métricas de comunicação como metáforas e formalidade do conteúdo dito dos vídeos. As métricas devem ser elencadas em uma escala de 1 a 10.

**Ator**: Sistema

**Fluxo de eventos**:
1. O sistema recebe a transcrição do vídeo
2. O sistema, através de processamento interno ou serviços externos, define o conteúdo do vídeo em uma escala entre 1 a 10 nos tópicos de formalidade e metáfora.
3. Salva as métricas encontradas relacionadas ao vídeo.


**Pré-condições**: O sistema deve estar em correto funcionamento e através de uma rotina ou rota obter a transcrição dos vídeos.

**Pós-condições**: O sistema deve manter-se em funcionamento e salvar as métricas dos vídeos transcritos.

#### RF4 - Obter Tópicos ditos nos vídeos

**Nome**: Obter métricas de comunicação dos vídeos

**Descrição**: A aplicação deve ser capaz de através da transcrição dos vídeos, obter tópicos do conteúdo dito dos vídeos. Os tópicos devem ser strings simples como “computação”, “indústria”, etc.

**Ator**: Sistema

**Fluxo de eventos**:
1. O sistema recebe a transcrição do vídeo
2. O sistema, através de processamento interno ou serviços externos, define tópicos do conteúdo do vídeo.

#### RF5 - Compilação de métricas dos vídeos

**Nome**: Compilação de métricas dos vídeos

**Descrição**: O sistema deve ser capaz de compilar as métricas dos vídeos transcritos e metrificados do usuário da seguinte forma: 
Deve-se salvar a data de compilação;
Deve-se metrificar o tempo, de 30 em 30 segundos com a contagem de vídeos nesse range, sua média de views, soma de views, média de comentários, soma de comentários, média de avaliações e soma de avaliações;
Deve-se, para cada valor entre 1 e 10 das métricas de comunicação salvas, metrificar a contagem de vídeos, sua média de views, soma de views, média de comentários, soma de comentários, média de avaliações e soma de avaliações;
Deve-se, para cada tópico único dos vídeos, metrificar a contagem de vídeos, sua média de views, soma de views, média de comentários, soma de comentários, média de avaliações e soma de avaliações;

**Ator**: Sistema

**Fluxo de eventos**:
1. O sistema através de uma rotina ou rota, executa a compilação dos dados
2. O sistema deve obter os vídeos metrificados
3. O sistema deve calcular as métricas de compilação definidas.
4. O sistema deve salvar a compilação dos dados.

**Pré-condições**: O sistema deve estar em correto funcionamento e através de uma rotina ou rota, compilar os dados dos vídeos já metrificados

**Pós-condições**: O sistema deve manter-se em funcionamento e salvar a compilação dos dados.

### Requisitos Não Funcionais

#### RNF1 - Resistência a Erros

**Nome**: Resistência a Erros

**Descrição**: O sistema deve ser resistente a erros, ou seja, caso ocorra alguma exceção relaciona a retornos inesperados de APIs, comunicações com sistema externos ou erro de lógica de programação, o sistema não deve ser desligado e deve permanecer ativo, podendo receber futuras comunicações sem a necessidade de um desenvolvedor religá-lo.

**Critério de aceitação**:

- O sistema não deve parar devido a erros relacionados à inserção incorreta de dados pelo usuário.
- O sistema não deve parar devido a respostas não esperadas de APIs e sistemas externos.
- O sistema não deve parar devido a erros de lógica durante a execução.

**Prioridade**: Alta

**Restrições**:

- Configurações de ambiente e tecnologias necessárias para a inicialização do sistema podem gerar erros, porém, esses erros não devem interromper a operação contínua do sistema.

### RNF2 - Desempenho na persistência de dados de métricas, transcrição e compilação

**Nome**: Desempenho na persistência de dados de métricas, transcrição e compilação

**Descrição**: A solução deve garantir eficiência no armazenamento de dados, salvando métricas, transcrição, quantidade de views, ratings e comentários em arquivos .json em um sistema de arquivos como S3, enquanto a referência dos vídeos e relacionamentos devem estar no mysql.

**Critérios de Aceitação**:

- O custo associado ao armazenamento de dados não deve exceder a capacidade máxima de armazenamento estabelecida para o serviço S3.

**Prioridade**: Média

**Restrições**:

- A eficiência de armazenamento não deve comprometer a integridade dos dados armazenados.

#### RNF3 - Processamento Paralelo de Transcrição e Retirada de Métricas

**Nome**: Processamento Paralelo de Transcrição e Retirada de Métricas

**Descrição**: O processamento de transcrição e o processamento de retirada de métricas são os processamentos mais demorados, portanto, através do uso de filas ou outras técnicas, esses processos devem ser executados em paralelo.

**Critérios de Aceitação**:

- O sistema deve conseguir executar simultaneamente ao menos uma transcrição e uma retirada de métricas.

**Prioridade**: Média

**Restrições**:

- O sistema deve utilizar técnicas para impedir a competição de recursos entre os dois processamentos


## Proposta de Arquitetura

Entendendo os requisitos da solução, com a finalidade de tornar possível suas implementações, foi desenhada a arquitetura de componentes a seguir, representada em um diagrama de implantação:

![image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/980252be-7f21-4a76-a098-98e70a7ca804)


Para começar a entendê-la, imagine o fluxo que ocorre quando alguma empresa acessa o dashboard da aplicação:

1. O browser cliente faz um requisição para o AWS EC2 que contém o frontend.
2. O AWS EC2 retorna uma resposta como HTML, JS e CSS, sendo a versão estática do frontend.
3. O Browser, através do código JS retornado, faz uma ou mais requisições para o backend pedindo as informações necessárias para montar visualmente os dados.
4. O AWS EC2 de backend recebe as requisições e pede informações de acordo com a necessidade para a API da SambaTech, RDS, S3, serviços da IBM de LNP e API de IA.
5. A API de IA conecta-se com o serviço do GPT para retirar métricas e devolve para o backend.
6. O AWS EC2 de backend trabalha as respostas recebidas e devolve para o browser cliente as informações em formato de json.
7. O Browser cliente recebe as informações e através do código JS do frontend contido, monta as visualizações necessárias.

Dessa maneira, percebe-se que o compoenente de Backend é um unificador de diversos serviços, enquanto o RDS e S3 são utilizados como uma camada de persistência e os componentes da IBM como serviços NLP. Ainda sim, outras caraterísticas devem ser consideradas:

- A resposta esperada da API da sambatech são os metadados de vídeos e seu arquivo ou endereço para o arquivo bruto. Dessa forma, o backend deve conseguir obter o arquivo de vídeo e por meio da integração com os serviços da IBM, adicionar mais um metadado importante para as análises: a legenda do vídeo.
- A API de IAs será uma API feita em python com flask que deve tornar possível a retirada das métricas ditas nos requisitos, seja utilizando modelos preditivos ou conexões externas. Como até o momento estamos apenas debatendo as métricas, apenas a conexão com GPT foi estabelecida, porém outras tecnologias ainda podem ser acrescentadas futuramente.
- A API de IAs deve retornar diversas informações (como as que estão presentes nos requisitos funcionais) que por motivos de otimização, devem ser salvas como metadados adicionais para análises futuras.
- O frontend funciona da maneira como foi exemplificado anteriormente pois usa REACT.JS em sua implementação
- O backend será em node.js devido ao conhecimento prévio dos integrantes do grupo.
- O S3 será utilizado como uma abordagem de performance, visto que banco de dados relacionais como MYSQL podem ter problemas em realizar queries em dados muito grandes como o texto gerado pelos vídeos.

Dessa forma, a implementação dos serviços estabelecidos no diagrama apresentado devem satisfazer os requisitos do projeto além de proporcionar outros benefícios:

- **Possibilidade de scalling futuro**: Como o projeto dura apenas 10 semanas, não queremos gastar muito tempo na configuração de scalling de componenetes que durante o desenvolvimento serão pouco usados. Ainda sim, a arquitetura foi projetada buscando separar os componentes mais diferentes entre si, possibilitando a configuração de scalling apenas no escopo do backend, por exemplo.
- **Simplicidade**: Apesar de ser uma proposta que resolve os desafios apresentados, ainda sim buscamos utilizar o mínimo de componentes possíveis para facilitar a implementação e teste desse MVP.
- **Otimização de Processamento**: Através de técnicas como o uso do S3 para metadados pesados e processamento prévio ao executar rotinas, buscamos trazer a página com todas as informações em poucos segundos, mesmo tendo uma quantidade enorme de processamento que precisa ser realizado por debaixo dos panos.

# Sprint 2

## Sistema de NLP

# Documentação da Sprint 2

## API Speech to Text e recebimento de audio
### Descrição
Esta seção documenta a API utilizada para converter áudio em texto, detalhando os endpoints disponíveis, os métodos HTTP suportados, os parâmetros de entrada, e as respostas esperadas. Exemplos de chamadas à API e respostas correspondentes são fornecidos para facilitar a integração.

**Endpoint:** /v1/test/audio

**Descrição do endpoint**

Este endpoint é responsável por receber um arquivo de áudio do frontend, conectar com a API Speech to Text da IBM utilizando as credenciais fornecidas, enviar a transcrição recebida para a API de reconhecimento de intenção criada e retornar as informações relacionadas a intenção. O processo envolve o recebimento do arquivo de áudio, o processamento intermediário necessário e a comunicação com a API da IBM e a API de Intenção para realizar a conversão de áudio em texto.

**Método HTTP Utilizado:** POST

**Parâmetros de Entrada**

- Formdata com parâmetro "file" (obrigatório): Parâmetro para enviar o arquivo de áudio que será convertido em texto e processado.

### Estrutura da API
**Estabelecendo Conexão**

Inicialmente, estabelecemos a conexão com a API da IBM, reconhecimento de intenção e banco de dados no arquivo app.ts através do método startConnections(), que invoca suas respectivas classes de "Providers" que iniciam as conexões utilizando as credenciais continadas nas variáveis de ambiente.

![alt text](img/setConfigurationApiSTT.png)

Figura x: Metódo startConnections

**Configuração do Middleware de Upload**

Utilizamos o multer, um middleware do Node.js, para lidar com multipart/form-data, que é usado para o upload de arquivos. A seguir, está detalhada a configuração do multer:

![alt text](img/multer_config.png)

Figura x: Configuração multer

- **Destination:** Determina o local de armazenamento dos arquivos enviados. Neste caso, é utilizado o diretório temporário do sistema operacional.

- **Filename:** Define o nome do arquivo dentro do diretório de destino, mantendo o nome original do arquivo enviado.

Essa configuração é passada para uma instância do multer, que retorna um middleware usado nas rotas específicas para gerenciar o upload de arquivos.

**Processamento de Áudio**

No arquivo TestController.ts, o método audio da classe TestController é responsável por receber e processar o áudio:

![alt text](img/TestControllerAudio.png)

Figura x: Metódo audio

Este método assíncrono extrai o arquivo enviado, salva-o em uma variável e utiliza o método getTranscription da classe TestService para enviar o arquivo à API da IBM. O método getTranscription utiliza as credenciais para autenticar a requisição e realizar a transcrição através do metódo recognize com os parametros settados em um objeto (metodo, url, dados e headers). Após receber o resultado, o backend usa o método getIntent que por sua vez, utiliza a transcrição para enviar uma requisição para a API de intenção. Seu resultado é uma string contendo a intenção do texto, que por sua vez é utilizada no método getDataByIntent, que retorna informações relacionadas a intenção.

![alt text](img/image.png)

Figura x: Função recognize

Abaixo podemos verificar como e estruturado o endpoint que faz a busca em nosso dataset para realizar o entendimento da intenção do usuário seguido de um exemplo de chamada para o mesmo.

![alt text](image-1.png)

Figura x: Endpoint da API de intenção

![alt text](img/req_intenção.png)

Figura x: Exemplo 1 de sucesso na requisição da API de intenção

Como observado, o método empregado é o POST, que aceita um JSON como parâmetro. Este JSON deve conter o campo 'text', que é armazenado através da transcrição resultante da nossa API, a qual está integrada com o serviço de conversão de fala em texto (Speech to Text) da IBM. O campo 'text' é essencial, pois contém o texto transcrito que será processado e analisado posteriormente pela nossa API de intenção. É importante garantir que o JSON enviado esteja bem-formado e que o campo 'text' contenha a transcrição correta para que a API funcione como esperado.

**Fluxo de Processamento**
1. O arquivo é recebido através do endpoint /v1/test/audio;
2. O multer processa o arquivo e o armazena temporariamente;
3. O método audio extrai o arquivo e o envia para transcrição;
4. A transcrição é retornada e o arquivo temporário é excluído;
5. Transcrição é recebida na API de inteção;
6. Retorna uma String com a intenção do texto falado;
7. Realiza busca pelo método getDataByIntent;
8. Retorna informações relacionadas a inteção do usuário.

**Resposta da API**
Em caso de sucesso, a API retorna o texto transcrito no formato JSON juntamente com os dados relacionado a intenção

![alt text](img/test_sucess.png)


Figura x: Exemplo 1 de sucesso na requisição da API

![alt text](img/test_graficos.png)

Figura x: Exemplo 2 de sucesso na requisição da API

Em caso de falha, a API retorna uma mensagem de erro apropriada, também em formato JSON.

![alt text](img/test_fail.png)

Figura x: Exemplo de falha na requisição da API

### Tipos de arquivos suportados
![alt text](image.png)

Figura x: Tabela com resumo de formatos de áudio suportados


## Algoritmo de NLP utilizado e sua implementação
A seção a seguir aprimora a descrição do algoritmo de Processamento de Linguagem Natural (PLN) utilizado em nosso sistema para identificar a intenção do usuário com base em uma frase fornecida. Esta documentação fornece uma visão abrangente do algoritmo, detalhando seu propósito, os princípios em que se baseia, seus benefícios e a implementação específica, incluindo as bibliotecas usadas, os procedimentos de configuração e exemplos de código que ilustram sua funcionalidade.

### Visão Geral do Algoritmo
O algoritmo de PLN implementado em nosso sistema é projetado para compreender e interpretar a linguagem humana, transformando texto em dados que o sistema pode manipular e analisar. A finalidade desse algoritmo é identificar a intenção por trás de uma frase inserida pelo usuário, facilitando uma interação mais eficaz e intuitiva com a plataforma. Utiliza-se uma combinação de técnicas de PLN, incluindo limpeza de texto, tokenização, remoção de palavras irrelevantes (stop-words), e vetorização para analisar o texto e extrair significados relevantes.

### Implementação do Algoritmo

**Limpeza de Texto**

Inicialmente, a função clean_text() utiliza a biblioteca re (regex) para eliminar caracteres não alfanuméricos e converter o texto para minúsculas, padronizando a entrada para as etapas subsequentes.

![alt text](img/funcao_clean_text.png)

**Tokenização**

Com a biblioteca spaCy, a função tokenizacao() decompõe o texto em palavras ou tokens individuais, permitindo que o algoritmo processe e entenda cada palavra de forma isolada.

![alt text](img/funcao_tokenizacao.png)

**Remoção de Stop-Words**

Utilizando a biblioteca nltk, a função remove_stopwords() elimina palavras comuns que não contribuem significativamente para o significado do texto, como preposições e conjunções, simplificando a análise.

![alt text](img/funcao_remove_stopwprds.png)

**Lematização**

A lematização é realizada pela biblioteca spaCy, que processa os tokens para retornar a forma base ou de dicionário das palavras, facilitando a comparação e análise de termos similares.

![alt text](img/funcao_lemmatization.png)

**Vetorização**

A função BowVectorizer converte texto em representações numéricas usando CountVectorizer da scikit-learn, criando um vetor que indica a frequência de cada palavra no texto. O DataFrame resultante organiza esses vetores, associando-os às intenções correspondentes.

![alt text](img/funcao_BowVectorizer.png)

**Pipeline de Processamento**

A função pipeline integra todas as etapas anteriores, proporcionando um fluxo de processamento coeso e eficiente, que prepara o texto para análise.

![alt text](img/funcao_pipeline.png)

**Função find_most_similar_intent**

A função find_most_similar_intent(input_text, df_bow) é o coração do nosso sistema de identificação de intenção. Ela recebe um texto de entrada e o DataFrame processado para determinar a intenção mais próxima do texto fornecido. Internamente, a função processa o texto de entrada através do pipeline estabelecido, vetoriza essa entrada e, utilizando a similaridade do cosseno, compara-a com os vetores no DataFrame para encontrar a correspondência mais próxima.

![alt text](img/funcao_nlp.png)

O exemplo abaixo demonstra como a função é aplicada na prática, recebendo uma frase e identificando a intenção correspondente, ilustrando a capacidade do algoritmo de interpretar e responder a consultas do usuário de maneira eficaz.

![alt text](img/funcao_intencao.png)

Com esta funcionalidade integrada ao nosso sistema, nosso objetivo é fornecer liberdade  ao usuário, proporcionando-lhe acesso rápido e eficiente a informações cruciais. Seja para se preparar de forma abrangente para uma reunião ou para gerar insights valiosos durante discussões corporativas, esta ferramenta está desenhada para enriquecer a experiência do usuário com dados relevantes ao toque de um botão.

Esta característica inovadora elimina a necessidade de interromper atividades ou depender de terceiros para obter informações pertinentes. Com um simples comando de voz, os usuários podem solicitar e receber dados essenciais em questão de segundos, permitindo-lhes permanecer focados e produtivos. Ao integrar esta funcionalidade, nosso sistema não apenas otimiza o fluxo de trabalho, mas também incentiva uma tomada de decisão mais informada e ágil dentro do ambiente empresarial.

### Benefícios do algoritmo utilizado
Entre os beneficios desse algoritmo temos a interpretabilidade, já que a representação Bag-of-Words (BoW) permite uma interpretação clara das características das mensagens. Cada palavra contribui diretamente para a construção do vetor, tornando fácil entender quais termos influenciam na decisão da intenção. Além disso também é um algoritmo eficiente já que a abordagem BoW simplifica o processo de vetorização e cálculo de similaridade. Isso resulta em uma implementação eficiente, especialmente quando comparada a modelos mais complexos, sendo adequada para sistemas com recursos computacionais limitados.

**Bibliotecas Utilizadas:**

1. pandas: Manipulação de dados em formato tabular. 
2. re: Expressões regulares para limpeza de texto. 
3. nltk: Ferramentas para processamento de linguagem natural (tokenização, stopwords). 
4. spacy: Biblioteca de processamento de linguagem natural usada para lematização. 
5. sklearn: Biblioteca para aprendizado de máquina, utilizando CountVectorizer para representação BoW e cosine_similarity para calcular a similaridade de cosseno.

**Configuração e Pré-requisitos:**

Download de modelos específicos do spaCy (pt_core_news_lg) e dos recursos do NLTK. Instalação de bibliotecas necessárias, se não estiverem presentes (pip install pandas scikit-learn spacy).

# Processo de Deploy em Nuvem

## Criação de Contas em Nuvem

### AWS (Amazon Web Services)

1. Acesse [https://aws.amazon.com/](https://aws.amazon.com/) e clique em "Crie uma conta da AWS".

   ![AWS Create Account](img/tela-inicial-aws.png)

2. Siga as instruções para criar uma nova conta AWS.

   ![AWS Signup Process](img/tela-cadastro-aws.png)

3. Após a criação, faça login no [Console AWS](https://aws.amazon.com/console/).

   ![AWS Console Login](img/tela-login-aws.png)

### IBM Cloud

1. Acesse [https://cloud.ibm.com/](https://cloud.ibm.com/) e clique em "Criar uma conta".

   ![IBM Cloud Signup](img/tela-inicial-ibm-cloud.png)

2. Siga as instruções para criar uma nova conta IBM Cloud.

   ![IBM Cloud Signup Process](img/tela-cadastro-ibm-cloud.png)

3. Após a criação, faça login no [IBM Cloud Dashboard](https://cloud.ibm.com/dashboard/).

   ![IBM Cloud Dashboard](img/tela-dashboard-ibm-cloud.png)



## Backend (Node.js)

### Criação, Configuração e Conexão da Instância EC2

1. Acesse o console da AWS e crie uma nova instância EC2 clicando em Executar. OBS: Na Seção "Par de chaves (login)", esteja ciente que ao criar um par de chaves de segurança você não deverá fornecê-la a terceiros e precisa guardá-la com segurança pois apenas com ela será possível se conectar na instância criada.

   ![Captura de Tela - Buscar serviço EC2](img/tela-servicos-aws.png)
   ![Captura de Tela - Dashboard EC2](img/tela-dashboard-ec2-aws.png)
   ![Captura de Tela - Criar Instância EC2](img/tela-criacao-instancia-ec2-aws.png)

2. Durante a criação, configure um grupo de segurança com uma regra de entrada para o TCP personalizado com intervalo de portas `5173`.

   ![Captura de Tela - Configurar Grupo de Segurança](img/tela-configurar-grupos-de-seguranca.png)

3. Conecte-se à instância utilizando SSH clicando em Conectar após marcar a instância criada.

   ![Captura de Tela - Instâncias EC2](img/tela-lista-instancias-ec2.png)

4. Clique no icone de copiar (abaixo da palavra "Exemplo") para copiar o comando de conexão à instância
   ![Captura de Tela - Conectar via SSH](img/tela-conectar-instancia-ssh.png)

5. Clique no icone de copiar (abaixo da palavra "Exemplo") para copiar o comando de conexão à instância
   ![Captura de Tela - Conectar via SSH](img/tela-conectar-instancia-ssh.png)

6. Para se conectar à instância remota localmente será necessário utilizar uma conexão SSH, para isso abra o terminal e entre na pasta que sua chave da instância está e cole o comando de conexão copiado anteriormente.
   ![Captura de Tela - Conectar de forma remota via SSH](img/tela-conexao-remota-ssh-ec2-aws.png)

### Instalação Docker e Git na Instância EC2

#### Utilize os comandos (Linux nesse caso) abaixo para instalar o Docker e o Git na máquina EC2

```bash
# Atualize o sistema operacional
sudo yum update -y

# Instale o Docker
sudo yum install docker -y
sudo service docker start
sudo usermod -a -G docker ec2-user

# Instale o Docker-Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Reinicie a conexão com a instância
exit
```

```bash
# Reconecte à instância
ssh -i "seu-arquivo-chave.pem" ec2-user@<endereço-ip>
```

```bash
# Instale o Git
sudo yum install git -y
```

### Clone do Repositório e Deploy

```bash
# Clone o repositório (utilize seu token de segurança do GitHub)
git clone https://<seu-token>@github.com/seu-usuario/2024-T0006-ES07-G02.git

# Acesse a pasta do backend
cd 2024-T0006-ES07-G02/src/backend

# Crie um arquivo .env com as variáveis de ambiente necessárias
echo "PORT=<sua-porta>" > .env
echo "DB_HOST=<seu-host>" >> .env
echo "DB_USER=<seu-usuario>" >> .env
echo "DB_PASSWORD=<sua-senha>" >> .env
echo "DB_DATABASE=<seu-banco>" >> .env
echo "DB_PORT=<sua-porta-db>" >> .env
echo "IBM_STT_BASE_URL=<sua-url>" >> .env
echo "IBM_STT_API_KEY=<sua-chave>" >> .env
```

```bash
# Execute o Docker Compose para iniciar a aplicação
docker-compose up -d --build
```

A aplicação backend estará acessível em [http://<endereço-ec2>:3000](http://<endereço-ec2>:3000).

### Criação do Recurso Speech to Text na IBM Cloud e obtenção da chave da API

1. Pesquise por "Speech to Text" na aba de busca da IBM Cloud.
   ![Captura de Tela - Buscar STT](img/tela-busca-recurso-STT-ibm-cloud.png)

2. Selecione o Serviço Speech to Text e crie o recurso na sua conta com as configurações desejadas (região, nome, tags, etc).
   ![Captura de Tela - Buscar STT](img/tela-criacao-recurso-STT-ibm-cloud.png)

3. Na aba Gerenciamento é possível obter as credenciais para uso do serviço através de API Key e URL. Copie a API_KEY e a URL e as defina como string de variável de ambiente no arquivo .env criado na pasta backend da instância EC2 do backend IBM_STT_API_KEY e IBM_STT_BASE_URL, consecutivamente. 
   ![Captura de Tela - Buscar STT](img/tela-criacao-recurso-STT-ibm-cloud.png)

## NLP API (Python FastAPI)

### Criação e Configuração da Instância EC2

1. Crie uma nova instância EC2 seguindo os passos anteriores.

2. Conecte-se à instância utilizando SSH.

### Instalação de Docker e Git na Instância EC2

Repita os mesmos passos para instalação de Docker e Git conforme descrito para o Backend.

### Clone do Repositório e Deploy

```bash
# Clone o repositório (utilize seu token de segurança do GitHub)
git clone https://<seu-token>@github.com/seu-usuario/2024-T0006-ES07-G02.git

# Acesse a pasta da NLP API
cd 2024-T0006-ES07-G02/src/nlp_api
```

```bash
# Execute o Docker Compose para iniciar a aplicação
docker-compose up -d
```

A NLP API estará acessível em [http://<endereço-ec2>:8000](http://<endereço-ec2>:8000).

## Frontend (React)

### Criação e Configuração da Instância EC2

1. Crie uma nova instância EC2 seguindo os passos anteriores.

2. Conecte-se à instância utilizando SSH.

### Instalação de Docker e Git na Instância EC2

Repita os mesmos passos para instalação de Docker e Git conforme descrito para o Backend.

### Clone do Repositório e Deploy

```bash
# Clone o repositório (utilize seu token de segurança do GitHub)
git clone https://<seu-token>@github.com/seu-usuario/2024-T0006-ES07-G02.git

# Acesse a pasta do frontend
cd 2024-T0006-ES07-G02/src/sorriso-maroto
```

```bash
# Instale o Vite globalmente
npm install -g vite
```

```bash
# Execute o Docker Compose para iniciar a aplicação
docker-compose up -d --build
```

A aplicação frontend estará acessível em [http://<endereço-ec2>](http://<endereço-ec2>).


# Sprint 3

# Documentação da Sprint 3

## Especificações

O sistema é constituído de 4 partes principais:
1 - Filtragem dos vídeos que devem ser processados
2 - Transcrição dos vídeos
3 - Processamento de texto dos vídeos (métricas)
4 - Compilação de resultados

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/f627f2aa-4d25-437b-8e1b-14ad87259407)

1 - Filtragem dos vídeos que devem ser processados
O processamento começa a partir de uma chamada cronjob que ocorre 1 vez ao dia. Os últimos vídeos são solicitados à API da sambatech e são cruzados com os vídeos que já temos registrado em banco com o objetivo de encontrar os que não foram processados ainda. Para cada vídeo, é criada uma mensagem na fila de transcrição, contendo o ID no payload.

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/6f41a8d6-71b5-4ce0-a3ec-3fff33487384)

2 - Transcrição dos vídeos
A API de transcrição consume a última mensagem da fila e pede o arquivo de vídeo para o backend, que por sua vez, pede para a API da sambatech e retorno para a API de transcrição. Depois de separar o áudio, enviamos para o Speech to Text para obter a transcrição e esse texto volta como uma requisição para o endpoint de webhook do backend. O Backend salva as informações no Banco e no S3 e cria uma mensagem na fila de gerar métricas com o ID no payload.

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/a7f0738f-f42b-4c42-bee1-6b1b01e95356)

3 - Processamento de texto dos vídeos (métricas)
A API de processamento de texto consome a última mensagem da fila de gerar métricas, obtem o id relacionado e requisita as informações salvas do vídeo ao backend, que resgata o que tem salvo do S3 e Banco. Depois, para cada métrica que combinamos, utilizando GPT, IBM NLU ou processamento interno, obtemos as métricas e retornamos todas elas de uma vez para o endpoint de webhook de métricas do backend. Por fim, essas informações são salvas no S3 e Banco.

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/4e60c71b-dbb6-4138-ad9b-ac9201d74245)


4 - Compilação de resultados
Assim, um cronjob que pode ocorrer todo dia também, acessa uma rota do backend que requisita as informações de todos os vídeos para o Banco e o S3. Ele compila essas informações e salva o resultado em uma tabela espeífica no Banco.

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/36b919c4-d20c-4175-8428-f60acb7672ca)



### Aplicação de Webhooks e estruturação do Backend

Webhooks são uma maneira de os aplicativos da web se comunicarem em tempo real. Eles funcionam através de callbacks HTTP, o que significa que um aplicativo pode enviar uma solicitação HTTP para outro aplicativo quando ocorre um evento específico. Com a aplicação de webhooks obtemos uma automação e a capacidade de manter sistemas sincronizados em tempo real, eliminando a necessidade de consultas repetitivas e aumentando a eficiência geral do sistema. 


#### Detalhação das rotas e endpoints 

As rotas e endpoints principais que utilizamos,com as informações sobre os métodos HTTP aceitos, como POST, e os formatos de dados esperados:

1. **Last Compiled (Última Compilação)**
   - Método HTTP: GET
   - URL: `{{ _.baseUrlBackend }}analytics/last`
   - Descrição: Esta rota busca informações sobre a última compilação.
   - Headers: User-Agent (Valor: insomnia/2023.5.8)

2. **Find Video (Encontrar Vídeo)**
   - Método HTTP: GET
   - URL: `{{ _.baseUrlBackend }}videos/1`
   - Descrição: Esta rota busca um vídeo específico com o ID fornecido.
   - Headers: User-Agent (Valor: insomnia/2023.5.8)

3. **List Videos (Listar Vídeos)**
   - Método HTTP: GET
   - URL: `{{ _.baseUrlBackend }}videos`
   - Descrição: Esta rota lista todos os vídeos disponíveis.
   - Headers: User-Agent (Valor: insomnia/2023.5.8)

4. **Transcript Webhook (Webhook de Transcrição)**
   - Método HTTP: POST
   - URL: `{{ _.baseUrlBackend }}webhooks/videos/transcription`
   - Descrição: Esta rota recebe dados de transcrição de vídeo.
   - Body: JSON no formato:
     ```
     {
         "id": 1,
         "transcription": "teste!"
     }
     ```
   - Headers: Content-Type (Valor: application/json), User-Agent (Valor: insomnia/2023.5.8)

5. **Metrics Webhook (Webhook de Métricas)**
   - Método HTTP: POST
   - URL: `{{ _.baseUrlBackend }}webhooks/videos/metrics`
   - Descrição: Esta rota recebe métricas de vídeo.
   - Body: JSON no formato:
     ```
     {
         "id": 1,
         "metaphor": 5,
         "formality": 10
     }
     ```
   - Headers: Content-Type (Valor: application/json), User-Agent (Valor: insomnia/2023.5.8)

6. **Process Videos (Processar Vídeos)**
   - Método HTTP: POST
   - URL: `{{ _.baseUrlBackend }}routines/videos/process-new`
   - Descrição: Esta rota processa novos vídeos.
   - Headers: User-Agent (Valor: insomnia/2023.5.8)

7. **Compile Videos (Compilar Vídeos)**
   - Método HTTP: POST
   - URL: `{{ _.baseUrlBackend }}routines/videos/compile`
   - Descrição: Esta rota compila vídeos.
   - Headers: User-Agent (Valor: insomnia/2023.5.8)

8. **Recognize (Reconhecer)**
   - Método HTTP: POST
   - URL: `https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/704b634d-d8ae-42c0-bc5e-6a9476f71b3d/v1/models/pt-BR_Multimedia/recognize`
   - Descrição: Esta rota envia um arquivo de áudio para reconhecimento de fala.
   - Body: Multipart form-data com o parâmetro "file" contendo o arquivo de áudio.
   - Headers: Content-Type (Valor: multipart/form-data), User-Agent (Valor: insomnia/2023.5.8), Authorization (Valor: Basic {credenciais de autenticação})


### Sistema de troca de mensagens

Para notificar os eventos, utilizamos o RabbitMQ, que atua como um intermediário entre aplicativos, permitindo que eles se comuniquem de forma assíncrona e distribuída. Facilitando a troca de mensagens entre diferentes partes de um sistema, ajudando a desacoplar componentes e permitindo uma arquitetura mais flexível e escalável. Além de permitir que os aplicativos enviem mensagens para filas, onde podem ser armazenadas temporariamente até serem processadas pelos consumidores. Isso ajuda a gerenciar a carga de trabalho e a evitar a perda de dados em caso de falha.


3.1 Descrição do sistema de mensagens: RabbitMQ. Explique como os tópicos, filas ou canais são configurados e utilizados para transmitir as notificações de eventos entre os componentes.

RabbitMQ é um intermediário de mensagens (message broker) que permite a comunicação entre diferentes partes de um sistema de forma assíncrona, distribuída e desacoplada. Utiliza o protocolo AMQP (Advanced Message Queuing Protocol) para garantir a entrega confiável de mensagens, permitindo a criação de arquiteturas complexas de microserviços ou sistemas distribuídos.

Tópicos, Filas e Canais:

Filas: São estruturas básicas onde as mensagens são armazenadas até serem consumidas. No RabbitMQ, uma fila é um buffer que armazena mensagens esperando pelos consumidores para processá-las. As filas são declaradas por consumidores ou produtores e podem ter várias configurações, como durabilidade, exclusividade e auto-delete.

Tópicos: São uma forma de roteamento de mensagens que permitem que os produtores enviem mensagens a múltiplas filas com base em um padrão de correspondência entre a chave de roteamento da mensagem e o padrão definido pelo consumidor. Isso é útil para transmitir mensagens a diferentes partes do sistema que estão interessadas em eventos específicos.

Canais: Um canal é uma conexão virtual dentro de uma conexão física do TCP/IP entre o aplicativo e o servidor RabbitMQ. Canais são utilizados para multiplexar uma conexão TCP, permitindo que várias filas, trocas e transações sejam gerenciadas por uma única conexão TCP.

Configuração e Uso:

Para transmitir notificações de eventos entre componentes usando RabbitMQ, primeiro define-se as filas e os tópicos. Isso geralmente envolve configurar uma "exchange", que é um componente do RabbitMQ responsável por receber mensagens dos produtores e encaminhá-las às filas adequadas com base no tipo de exchange (direto, tópico, fanout, headers) e nas regras de roteamento.

Exchanges de Tópicos: Permitem o roteamento flexível de mensagens para uma ou mais filas com base em padrões de correspondência entre a chave de roteamento da mensagem e o padrão definido na binding (ligação) entre a exchange e a fila.

Configuração da Fila: Ao configurar uma fila, pode-se especificar diversas propriedades, como durabilidade (persistente ou não), exclusividade e política de auto-delete. Essas propriedades determinam como as mensagens são gerenciadas e retidas no sistema.

3.2 Detalhes sobre produtores e consumidores: Descreva como os produtores de mensagens são configurados no backend para enviar notificações de eventos relevantes, e como os consumidores são configurados em outros componentes para processar essas mensagens e realizar as ações necessárias.
Produtores:

Produtores são componentes ou serviços que enviam mensagens para o RabbitMQ. Para configurar um produtor, é necessário:

Estabelecer uma conexão com o servidor RabbitMQ.
Abrir um canal dentro dessa conexão.
Declarar a exchange para a qual a mensagem será enviada, especificando seu tipo e propriedades.
Publicar a mensagem na exchange, fornecendo a chave de roteamento necessária e a mensagem em si.
O produtor decide para qual exchange enviar a mensagem, mas não se preocupa diretamente com a fila em que a mensagem será armazenada; isso é determinado pelas regras de roteamento da exchange.

Consumidores:

Consumidores são serviços ou componentes que recebem e processam mensagens. Para configurar um consumidor, realiza-se os seguintes passos:

Estabelecer uma conexão com o servidor RabbitMQ.
Abrir um canal dentro dessa conexão.
Declarar a fila da qual as mensagens serão consumidas. Se necessário, também declarar a exchange e as bindings.
Registrar um callback (função de retorno) que será chamado sempre que uma mensagem for entregue na fila.
Os consumidores escutam as filas e processam as mensagens recebidas. Eles podem enviar uma confirmação (acknowledgment) de volta ao RabbitMQ após o processamento da mensagem, o que garante que a mensagem seja marcada como processada e removida da fila.

Desacoplamento e Escalabilidade:

Esta arquitetura permite o desacoplamento entre produtores e consumidores; os produtores não precisam conhecer os detalhes dos consumidores e vice-versa. Além disso, facilita a escalabilidade, pois novos consumidores podem ser adicionados para processar mensagens de filas específicas sem alterar a configuração dos produtores ou a lógica de roteamento do sistema.

### Frontend

<!-- 4. Um frontend mínimo para realizar o teste da implementação do modelo:
4.1 Descrição da interface do usuário: Documente a estrutura e os componentes da interface de usuário mínima desenvolvida, incluindo campos de entrada, botões e elementos de exibição de resultados.
4.2 Integração com as APIs do backend: Explique como o frontend se conecta ao backend por meio de chamadas de API, fornecendo exemplos de como enviar dados de texto ou áudio para processamento e receber os resultados obtidos.
4.3 Instruções de uso e testes: Forneça instruções detalhadas sobre como utilizar o frontend para testar a implementação do modelo. Isso pode incluir guias passo a passo para inserir os dados corretamente, realizar o processamento e visualizar os resultados. -->
### Documentação Detalhada: Interface do Usuário, Integração com APIs e Instruções de Uso e Testes

### 4. Descrição da Interface do Usuário, Integração com APIs e Instruções de Uso e Testes

**4.1 Descrição da Interface do Usuário:**

A interface do usuário (UI) é dividida em três seções principais:

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/6d0db67f-b59f-40d5-8577-673ac6267779)

**1. Área de Entrada:**

* **Campo de texto:** Permite inserir o texto ou frase a ser analisada.
* **Microfone:** Captura áudio para análise de voz.

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/dc5aeef3-8bef-4565-b63a-191f52c64f73)

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/f8d02464-6d8e-442c-8f93-f72d64babec1)

* **Botão de pesquisa:** Inicia o processo de análise e exibe os resultados na área de visualização.

**2. Área de Visualização:**

* **Tabela:** Exibe os resultados da análise em formato tabular, com colunas para métricas relevantes (sentimento, entidades, tópicos, etc.).
* **Gráficos:** Apresentam visualizações gráficas das métricas, facilitando a compreensão dos dados.
* **Resumo:** Fornece uma visão geral dos resultados da análise, com informações como sentimento geral, entidades mais frequentes, tópicos principais, etc.

**3. Área de Configurações:**

* **Opções de personalização:** Permitem ao usuário personalizar a interface e os resultados da análise (cores, idioma, formato de data, etc.).
* **Ajuda e documentação:** Fornecem informações sobre o sistema e instruções de uso.

**Componentes da UI:**

* **Campos de entrada:** Campo de texto e microfone para inserir o conteúdo a ser analisado.
* **Botões:** Botão de pesquisa e outros botões para navegação e configurações.
* **Elementos de exibição de resultados:** Tabela, gráficos, resumo e outros elementos visuais para apresentar os resultados da análise.

**Observações:**

* A UI foi projetada para ser simples, intuitiva e acessível, facilitando o uso do sistema por usuários com diferentes níveis de experiência.
* O uso de cores, ícones e outros elementos visuais contribui para a melhor compreensão dos resultados.
* A área de configurações permite que os usuários personalizem sua experiência de acordo com suas necessidades.

**4.2 Integração com as APIs do Backend:**

O frontend se conecta ao backend por meio de APIs RESTful que fornecem acesso às funcionalidades do sistema. As APIs são responsáveis por:

* **Receber dados do frontend:** Texto, áudio, configurações de análise, idioma, etc.
* **Processar dados no backend:** Realizar a análise de texto ou áudio utilizando o modelo de linguagem e outros recursos de NLP.
* **Retornar resultados para o frontend:** Métricas, entidades, tópicos, visualizações gráficas, etc.

**Exemplos de chamadas de API:**

* **Análise de texto:**

```json
POST /api/analise/texto

{
  "texto": "Este é um exemplo de texto para análise.",
  "idioma": "pt-br"
}
```

* **Análise de áudio:**

```json
POST /api/analise/audio

{
  "audio": {
    "data": "audio.wav",
    "formato": "wav",
    "idioma": "pt-br"
  }
}
```

**Autenticação e segurança:**

As APIs usam autenticação por token para garantir a segurança das chamadas. O token é gerado pelo backend e enviado no cabeçalho da requisição.

**4.3 Instruções de Uso e Testes:**

**1. Inserindo dados:**

* Digite o texto ou frase a ser analisada no campo de texto.
* Clique no botão de pesquisa para iniciar a análise.
* Para usar o microfone, clique no ícone e fale o texto que deseja analisar.
* As opções de filtro permitem refinar os resultados da análise por parâmetros específicos.

**2. Visualizando resultados:**

* A tabela, os gráficos e o resumo apresentarão os resultados da análise.
* Utilize as opções de filtro para refinar os resultados.
* Clique em uma linha da tabela para visualizar detalhes específicos da análise.

**3. Testando a implementação do modelo:**

* Insira dados de teste com diferentes características (sentimento, entidades, tópicos, etc.).
* Observe os resultados da análise e compare-os com o esperado.
* Repita o processo com diferentes tipos de dados (texto, áudio) e configurações para testar a robustez do modelo.
* Documente os resultados dos testes e identifique falhas, se houver.

**Exemplos de testes:**

* Analisar um texto com sentimento positivo e negativo.
* Analisar um áudio com tom neutro e intenção informativa.
* Analisar um texto com diferentes entidades.
* Analisar um áudio com diferentes emoções.


# Sprint 4

## Construção do Frontend da Solução

## Documentação da Sprint 4

A documentação abrange todos os aspectos cruciais relacionados à implementação e teste do frontend, bem como a integração com o backend. Inclui detalhes abrangentes, desde os requisitos funcionais e não funcionais do projeto até os wireframes ou protótipos de design. Além disso, fornece instruções detalhadas para configurar o ambiente de desenvolvimento e o código fonte do frontend implementado. No que diz respeito aos testes, são abordados o plano de testes, casos de teste e relatórios de teste para garantir a qualidade do frontend. Também são incluídas instruções passo a passo para a integração do frontend com o backend, juntamente com os testes de integração necessários. Adicionalmente, são descritas as etapas para o deploy da solução, desde a configuração do servidor até os testes finais realizados no ambiente de produção. Por fim, são fornecidas orientações detalhadas para monitorar o desempenho da solução em produção, realizar manutenção regular e solucionar problemas comuns.


## Requisitos do Sistema
Na documentação da Sprint 1, foram detalhados os Requisitos Funcionais (RF) que descrevem as funcionalidades específicas do sistema e os Requisitos Não Funcionais (RNF) que estabelecem critérios de qualidade em áreas como desempenho, segurança e usabilidade. Eles foram cuidadosamente priorizados com base na sua importância para o sucesso do projeto.

Ao longo das sprints seguintes, nosso foco é implementar e testar cada um desses requisitos, garantindo que nossa solução final atenda plenamente às expectativas dos usuários e stakeholders da SambaTech.
### Funcionalidades Específicas

#### Interação por Voz (RF1)
- **Descrição:** A solução oferecerá às empresas usuárias da plataforma a capacidade de interagir de forma eficaz com os dados analíticos gerados. Por meio de recursos de áudio, as empresas poderão solicitar informações específicas, como quais vídeos são os mais visualizados ou menos visualizados, os temas mais abordados, entre outras análises pertinentes.
- **Ator:** Empresa
- **Fluxo de eventos:**
    1. O colaborador da empresa aciona um botão designado para interação por voz em nosso dashboard.
    2. O colaborador envia um áudio solicitando informações específicas para entender mais facilmente os insights gerados pela plataforma.
    3. A solução utiliza a API do IBM Watson Assistant para transcrever o áudio em texto.
    4. A solução realiza uma busca no banco de dados, que contém os dados estatísticos sobre os vídeos que estão na plataforma, por meio da API do ChatGPT.
    5. O sistema retorna ao colaborador as informações solicitadas com base na correspondência com o áudio enviado.
- **Pré-condições:** Os dados estatísticos sobre os vídeos que estão na plataforma devem estar armazenados em um banco de dados na AWS, e a API da solução deve estar integrada com a API do ChatGPT.
- **Pós-condições:** A resposta fornecida ao colaborador deve corresponder precisamente à solicitação feita por áudio.

#### Exibição dos Trending Topics (RF2)
- **Descrição:** A solução deve ser capaz de metrificar os tópicos mais populares dentre os abordados dentro dos vídeos e apresentar como uma tabela no dashboard com nome e média de visualizações.
- **Ator:** Empresa
- **Fluxo de eventos:**
    1. A empresa acessa o dashboard da aplicação.
    2. A aplicação recolhe os metadados dos vídeos do sistema, relacionados à empresa.
    3. Deverá ser feita a média de visualização de cada tópico de acordo com os vídeos em que aparecem.
    4. Os resultados são apresentados através de uma tabela com nome do tópico e média de visualizações.
- **Pré-condições:** Os dados transcritos das vídeo aulas e tópicos identificados devem estar armazenados em um banco de dados na AWS, e a API da solução deve estar integrada com a API do ChatGPT.
- **Pós-condições:** A resposta do sistema em formato de tabela deve representar corretamente os tópicos mais vistos nos vídeos da empresa.

### Interfaces de Usuário

#### Dashboard de Análise
- **Descrição:** O dashboard de análise oferece uma interface intuitiva para que os usuários possam visualizar e interagir com os dados analíticos gerados pela plataforma.
- **Componentes:**
    - Gráficos interativos para visualização de métricas de comunicação.
    - Tabela de Trending Topics com média de visualizações.
    - Opções de filtro e seleção para personalização dos dados exibidos.

### Desempenho

#### Tempo de Resposta (RNF1)
- **Descrição:** A solução deve garantir que o tempo de resposta para as interações por voz não exceda 3 segundos e esteja disponível 99,9% do tempo.
- **Critério de aceitação:**
    - O tempo de resposta para todas as interações por voz deve ser medido a partir do momento em que o botão de interação é acionado até que a resposta seja recebida pelo estudante.
    - O sistema deve ser capaz de processar e responder às solicitações do estudante dentro do prazo estabelecido de 3 segundos, sob condições normais de carga de trabalho e conectividade.
- **Prioridade:** Alta
- **Restrições:**
    - A latência de rede e o desempenho dos serviços de transcrição e busca de informações podem afetar o tempo de resposta e devem ser considerados durante o desenvolvimento e teste da solução.

### Segurança

#### Segurança da Informação (RNF4)
- **Descrição:** A solução deve garantir a segurança da informação, protegendo dados sensíveis e impedindo acessos não autorizados.
- **Critério de aceitação:**
    - A comunicação entre o sistema e o banco de dados deve ser criptografada, utilizando protocolos seguros como HTTPS.
    - Mecanismos de autenticação robustos devem ser implementados para garantir que apenas usuários autorizados tenham acesso ao sistema.
- **Prioridade:** Alta
- **Restrições:**
    - O acesso aos dados sensíveis deve ser restrito apenas a usuários autorizados, de acordo com os princípios de privacidade e conformidade com regulamentações aplicáveis.

## Wireframe
Para a aplicação do projeto, utilizamos uma unica página para exibir o dashboard. Desenvolvemos o mockup idealizando informações que consideramos necessárias. Portanto, com as sprints de validações visamos a necessidade de melhorar a visualização do usuário, alterando que tipo de gráfico irá exibir tal informação. 

![Image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/99493861/9de774e0-fa54-4e6e-8667-2b029a1fd063)

## Configuração do Ambiente de desenvolvimento

Durante a sprint 4, os serviços planejados nas sprints anteriores foram efetivamente construídos e integrados. Dessa forma, nessa seção estão as instruções para a execução do ambiente de desenvolvimento de todos os serviços que compõem a solução.

#### Sistema de arquivos em Bucket - S3

O código precisa de um sistema de arquivos em bucket pois é com essa configuração que a solução está preparada para salvar as informações de metadados dos vídeos em arquivos .json. Dessa forma, é necessária a criação de um bucket no serviço S3 da AWS (você pode seguir [esse tutorial](https://docs.aws.amazon.com/pt_br/AmazonS3/latest/userguide/creating-bucket.html)) e em seguida preencher as variáveis de acesso da conta AWS criadora do bucket nas variáveis de ambiente da API de  backend.

#### Sistema de mensageria - RabbitMQ

O RabbitMQ é o sistema de mensageria utilizado pela solução. Através dele, a API de backend, coração do sistema, irá comunicar-se com os outros serviços. Para instalá-lo em ambiente de desenvolvimento, sugerimos que use o Docker através da seguinte linha de comando:

```
docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.13-management
```

Agora o sistema de mensageria está configurado. As mensagens serão publicadas e consumidas através da porta 5672 e o painel de controle das filas e mensagens pode ser visto a partir do endereço local http://localhost:15672.

#### Banco de Dados - Mysql

O banco de dados da aplicação onde ficarão registros dos processamentos de recolhimento de métricas e transcrições dos vídeos, além da entidade vídeo em sí pode ser criado em ambiente de desenvolvimento através do seguinte comando Docker:

```
docker run -d --name meu-mysql -e MYSQL_ROOT_PASSWORD=minhaSenha -p 3306:3306 mysql
```

Em seguida, deve-se criar as tabelas necessárias para o funcionamento da aplicação. Para tal, durante o desenvolvimento foi utilizado o software livre DBeaver ([link para download](https://dbeaver.io/download/)). Utilizando-o, acesse o banco de dados através das credenciais configuradas pelo docker e execute a seguinte query para criação das tabelas:

```
CREATE DATABASE `analysis_dashboard` /*!40100 DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci */ /*!80016 DEFAULT ENCRYPTION='N' */;

CREATE TABLE `queue_process` (
  `id` int NOT NULL AUTO_INCREMENT,
  `relation_id` int DEFAULT NULL,
  `queue` varchar(100) NOT NULL,
  `status` varchar(100) NOT NULL,
  `created_at` datetime DEFAULT CURRENT_TIMESTAMP,
  `updated_at` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `finished_at` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=1696 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

CREATE TABLE `video` (
  `id` int NOT NULL AUTO_INCREMENT,
  `external_id` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `metadata_file_path` varchar(255) DEFAULT NULL,
  `has_speak` tinyint DEFAULT NULL,
  `status` varchar(255) DEFAULT NULL,
  `title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,
  `created_at` datetime DEFAULT CURRENT_TIMESTAMP,
  `updated_at` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  UNIQUE KEY `video_UN` (`external_id`)
) ENGINE=InnoDB AUTO_INCREMENT=1934 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

Dessa forma o banco de dados estará configurado para a conexão do backend.

#### Backend - Node.js

A API de backend é a API que será acessada pelo frontend e criará as chamadas de processamentos necessárias para o correto funcionamento do sistema, além de conectar-se com a API da SambaTech. Seu código está escrito em node.js utilizando principalmente o framework express e o superset typescript. O arquivo de configuração principal da API que contém todas as bibliotecas, versões e scripts pode ser encontrado [neste link](../src/backend/package.json).

Para sua configuração, crie um arquivo com o nome “.env” na raíz do projeto de backend, ou seja, no caminho 2024-T0006-ES07-G02/src/backend/.env. Dentro desse arquivo, ficarão todas as variáveis de ambiente como endereços de conexão e configurações gerais da API. Dessa forma, preencha o arquivo seguindo esses campos, mas trocando os valores pelos endereços de conexão gerados localmente:

```
PORT="3000"
RABBIT_MQ_HOST="HOST de seu rabbitMQ”
RABBIT_MQ_USER="User de seu rabbitMQ"
RABBIT_MQ_PASSWORD="Senha de seu rabbitMQ"
RABBIT_MQ_PORT="Porta de seu rabbitMQ (geralmente 5672)"
DB_HOST="HOST de seu banco de dados"
DB_USER="User de seu banco de dados"
DB_PASSWORD="Senha de seu banco de dados"
DB_DATABASE="analysis_dashboard"
DB_PORT="Porta de seu banco de dados (geralmente 3306)"
S3_BUCKET_NAME="Seu Bucket criado no S3"
AWS_ACCESS_KEY_ID="ACCESS_KEY_ID de sua AWS"
AWS_SECRET_ACCESS_KEY="AWS_SECRET_ACCESS_KEY de sua AWS"
AWS_SESSION_TOKEN="AWS_SESSION_TOKEN de sua AWS"
SAMBA_VIDEOS_BASE_URL="http://api.sambavideos.sambatech.com/v1/"
SAMBA_VIDEOS_ACCESS_TOKEN="O AccessToken de seu projeto no samba vídeos"
SAMBA_VIDEOS_PID="O PID de seu projeto no samba vídeos"
IBM_STT_BASE_URL="https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/{Seu id de instância IBM STT aqui}"
IA_API_BASE_URL="A base da URL da API de NLP (ex: http://localhost:8000/"
```

Agora, para executar a aplicação, recomenda-se instalar localmente em sua máquina o node.js na versão 18.16.0. Em seguida, no diretório 2024-T0006-ES07-G02/src/backend, rode os comandos:

Instalação das dependência configuradas no package.json:
```
npm i
```

Execução do script de start da API em desenvolvimento:
```
npm run dev
```

Dessa forma a API estará corretamente configurada e pronta para uso.

#### API de Transcrição - Node.js

A API de transcrição é responsável pela regra de negócio da transcrição de vídeos. Seu processamento começa ao consumir as mensagens na fila ‘transcription’ publicadas pelo backend. Em seguida, irá transformar os vídeos em áudio e enviar para a IBM a fim de obter a transcrição dos vídeos para enviar à rota de webhook do backend. 

O código desta API está escrito em node.js utilizando principalmente o framework express e o superset typescript. O arquivo de configuração principal da API que contém todas as bibliotecas, versões e scripts pode ser encontrado [neste link](../src/transcription_api/package.json).

Para sua configuração, crie um arquivo com o nome “.env” na raíz do projeto de da API de transcrição, ou seja, no caminho 2024-T0006-ES07-G02/src/transcription_api/.env. Dentro desse arquivo, ficarão todas as variáveis de ambiente como endereços de conexão e configurações gerais da API. Dessa forma, preencha o arquivo seguindo esses campos, mas trocando os valores pelos endereços de conexão gerados localmente:

```
PORT="3001"
BACKEND_BASE_URL="URL base do backend (ex: http://localhost:3000/v1)/"
IBM_API_KEY='Sua chave da IBM aqui'
IBM_SERVICE_URL='https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/{Seu ID de instância aqui}'
RABBITMQ_URL=Sua string de conexão com o rabbitMQ( ex: 'amqp://admin:admin@localhost:5672)'
```

Para executar a aplicação, também recomenda-se instalar localmente em sua máquina o node.js na versão 18.16.0. Em seguida, no diretório 2024-T0006-ES07-G02/src/transcription_api, rode os comandos:
```
npm i
```

Execução do script de start da API em desenvolvimento:
```
npm run start
```

Dessa forma a API estará corretamente configurada e pronta para uso.

#### API de métricas (NLP API) - Python

A API de métricas é responsável por realizar todo o processamento para retirar as métricas dos textos transcritos dos vídeos. Dessa forma, a linguagem python foi escolhida devido a sua grande acessibilidade de pacotes para realizar a manipulação de dados dessa forma. As bibliotecas necessárias estão configuradas [nesse link](../src/nlp_api/requirements.txt).

Para sua configuração, crie um arquivo com o nome “.env” na raíz do projeto de da API de transcrição, ou seja, no caminho 2024-T0006-ES07-G02/src/nlp_api/.env. Dentro desse arquivo, ficarão todas as variáveis de ambiente como endereços de conexão e configurações gerais da API. Dessa forma, preencha o arquivo seguindo esses campos, mas trocando os valores pelos endereços de conexão gerados localmente:

```
gpt_key = "Sua chave do chatGPT"
ibm_nlu_key = "Sua chave do serviço de NLU da IBM"
rabbit_connection = "Sua query de conexão rabbitmq (ex: amqp://admin:admin@localhost:5672/)"
queue_name = "fila onde o backend irá publicas as mensagens (padrão: get_metrics)"
url_nlu = "URL base da API de NLU"
rabbit_username = "Username de seu rabbitMQ"
rabbit_password = "Senha de seu rabbitMQ"
rabbit_host = "Host de seu rabbitMQ"
backend_host="Base da URL do backend (ex: http://localhost:3000/v1/)"
```

Para executar a aplicação, também recomenda-se instalar localmente em sua máquina o python na versão 3.10.12. Em seguida, no diretório 2024-T0006-ES07-G02/src/nlp_api, rode os comandos:
```
pip install --no-cache-dir -r requirements.txt
```

Execução do script de start da API em desenvolvimento:
```
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

Dessa forma a API estará corretamente configurada e pronta para uso.

#### Frontend - React.js com Vite

O frontend da Aplicação é responsável por mostrar os dados ao usuário final. Ele irá conectar-se diretamente ao backend e realizar requisições HTTP para solicitar dados. O código foi desenvolvido utilizando javascript com a lib React.js e o superset Typescript. O arquivo de configuração principal da API que contém todas as bibliotecas, versões e scripts pode ser encontrado [neste link](../src/sorriso-maroto/package.json).

Como o código ficará no browser do cliente em tempo de execução, não foi criado um arquivo de variável de ambiente. Para executar as chamadas para o seu backend é necessário conferir e alterar o endereço contido no atributo “baseUrl” do arquivo nesse caminho: 2024-T0006-ES07-G02/src/sorriso-maroto/src/services/backendService.ts.
```
npm i
```

Execução do script de start da API em desenvolvimento:
```
npm run dev
```

Dessa forma o frontend estará corretamente configurado e pronto para uso.

## Código fonte do frontend
O projeto segue a seguinte hierarquia de pastas:

- **src/assets**: Contém os recursos estáticos do projeto, como imagens em SVG.
- **src/components**: Esta pasta é onde os componentes React reutilizáveis são armazenados. Isso inclui componentes como botões, barras de navegação, formulários, etc.
    - **src/components/Dashboard**: Esta pasta contém componentes específicos relacionados ao painel de informações da aplicação.
    - **src/components/Footer**: Este componente representa o rodapé da página.
    - **src/components/Input**: Este componente é um componente reutilizável para entrada de dados, como campos de formulário.
    - **src/components/Navbar**: Este componente representa a barra de navegação superior do aplicativo.
    - **src/components/Title**: Este componente é usado para exibir títulos ou cabeçalhos em diferentes partes do aplicativo.
- **src/pages**: Aqui ficam os componentes que representam páginas inteiras da aplicação. Cada arquivo nesta pasta representa uma página diferente do site.
    - **src/pages/Dashboard**: Esta pasta contém componentes específicos relacionados à página do painel de informações da aplicação.
    - **src/pages/Home**: Esta pasta contém componentes relacionados à página inicial do aplicativo.
    - **src/pages/Notfound**: Esta página é renderizada quando uma rota não correspondente é acessada.
    - **src/pages/Test**: Esta pasta contém componentes de teste ou protótipos de páginas que não são usados no ambiente de produção.
- **src/router**: Esta pasta contém a configuração do roteador da aplicação, que mapeia URLs para componentes React específicos.
    - **src/router/router.tsx**: Este arquivo contém a configuração do roteador da aplicação, onde as rotas são definidas e mapeadas para os componentes correspondentes.
- **src/services**: Aqui ficam os serviços da aplicação, como a lógica de acesso a APIs externas, gerenciamento de estado global, etc.
- **src/utils**: Esta pasta contém utilitários ou funções auxiliares que são usados em todo o projeto.

Os arquivos específicos também têm suas funções:

- **App.tsx**: Este é o componente principal da aplicação React. Ele provavelmente contém a estrutura básica do aplicativo, como a definição do layout global, a configuração do roteador, etc.
- **index.css**: Este é o arquivo de estilo principal da aplicação, onde você define estilos globais que se aplicam a toda a aplicação.
- **main.tsx**: Este é o ponto de entrada principal da aplicação, onde o aplicativo React é montado e renderizado na página HTML.
- **vite-env.d.ts**: Este arquivo é uma definição de tipo para o Vite, fornecendo informações sobre o ambiente de construção para o TypeScript.

Com os componentes React sendo os principais blocos de construção do aplicativo. React é usado para construir a interface do usuário, TypeScript adiciona tipagem estática ao código para melhorar a robustez e a manutenção, e Vite é utilizado como a ferramenta de construção para compilar e empacotar o código fonte do frontend, fornecendo uma experiência de desenvolvimento rápida e eficiente.

## Testes de integração e do frontend implementado 
Essa parte da documentação serve como um recurso abrangente para entender e colaborar eficazmente nos testes de integração e do frontend implementado. O link fornecido abaixo direcionará os interessados a este recurso essencial, garantindo transparência e colaboração eficaz em relação aos testes do frontend implementado.

[Documentação dos Testes do Frontend Implementado](https://docs.google.com/document/d/1RtZCkZOklDDjX7dNJEUUpdjkWJ79R5pfNiqyMTVrlz4/edit?usp=sharing)


## Deploy, Configuração do Servidor e Scripts de implantação

Para realizar o deploy da solução, foram utilizados serviços da AWS, sendo eles:

- 5 instâncias EC2 t2.micro Amazon Linux atreladas cada uma a uma instância do Elastic IP 
  - 4 dessas instâncias devem ter 15 GB de disco
- Uma instância RDS Mysql para o banco de dados
- Uma instância S3

A seguir, uma breve explicação do processo de implantação no ambiente da AWS. AS funções de cada API e serviço da solução estão descritas mais detalhadamente no guia de implantação no ambiente de desenvolvimento.

#### S3

Para criar um bucket no S3, siga [esse tutorial](https://docs.aws.amazon.com/pt_br/AmazonS3/latest/userguide/creating-bucket.html). Salve o nome criado pois precisará para criar as variáveis de ambiente da API de backend.

#### Instância RDS

O RDS é o serviço da AWS que permite a criação e manutenção de bancos de dados relacionais em nuvem. Você pode criar uma instância Mysql seguindo [esse tutorial](https://aws.amazon.com/pt/getting-started/hands-on/create-mysql-db/). Salve as credenciais de acesso e garanta que seu banco de dados esteja acessível.

#### Instâncias EC2

Para a configuração de uma instância EC2, veja esse tutorial. A seguir estão as peculiaridades e processos após a criação do EC2 para cada serviço.

##### RabbitMQ

Assim como no ambiente de desenvolvimento, acesse o EC2 criado através de uma conexão ssh e instale o Docker, para em seguida executar a instanciação do container RabbitMQ:

Instalação do Docker
```
sudo yum install -y docker
sudo service docker start
sudo usermod -a -G docker ec2-user
```

Instanciação do container RabbitMQ:
```
docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.13-management
```

Garanta que os grupos de segurança atrelados ao EC2 estejam com o acesso TCP para as portas 5672 e 15672 liberados.

##### NLP API, Transcription API, BackendAPI e Frontend

Para esses quatro serviços, o deploy será muito parecido:

Instale o GIT:
```
sudo yum install git
```

Instale o Docker:
```
sudo yum install -y docker
sudo service docker start
sudo usermod -a -G docker ec2-user
```

Instale o Docker Compose:
```
sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose version
```

Gere e copie uma chave SSH para o acesso ao repositório:
```
ssh-keygen -t ed25519 -C "seu-email-aqui"
cat ~/.ssh/id_ed25519.pub
```

Copie o conteúdo e adicione como valor em uma nova chave SSH em seu github acessando o menu Settings > SSH and GPG keys > New SSH key.

Alocando Memória SWAP

Para os serviços em Node.js, os deploys configurados nos arquivos de Docker realizam a build otimizada, o que exige mais RAM que o normal durante a execução da aplicação. Portanto, a alocação de memória SWAP é uma solução que consiste em reservar espaço do disco para ser usado como memória RAM. Dessa forma, além de preparar o ambiente para o caso da build, a aplicação resistirá a mais acessos simultâneos.

Configuração para ativar o SWAP:
```
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

Configuração para início de SWAP automático:

```
nano /etc/fstab

# Adicione essa linha no final do arquivo:
/swapfile swap swap defaults 0 0
```

```
sudo mount -a
```

Clonando repositório

Vá até a pasta /etc/ e execute o comando:

```
git clone git@github.com:Inteli-College/2024-T0006-ES07-G02.git
```
Agora o código está atualizado conforme a branch main do github. Verifique o guia de implantação do ambiente de desenvolvimento e configure as variáveis de ambiente conforme descrito. A execução do código em ambiente de produção está configurada em dois arquivos em cada serviço da solução: 
Dockerfile (configuração micro do container)
docker-compose.yml (configuração de portas e SO)
A seguir, criaremos um script sh e um serviço linux para que acesse esses arquivos de configuração e iniciem o container das APIs ou frontend.

Criando Script para atualização e configuração de container:

Criaremos um arquivo .sh onde ficará o script para a atualização do código e configuração do container docker preparado. Para isso, crie um arquivo chamado rebuild-service na pasta /etc/:
```
sudo mkdir /etc/project-shs
sudo nano /etc/project-shs/rebuild-service.sh

```

Preencha-o com esse conteúdo:
```
#!/bin/bash

cd /etc/2024-T0006-ES07-G02/src/{pasta-do-projeto}
git pull

docker-compose down
docker system prune -a
docker-compose up --build -d

```

Certifique-se de substituir {pasta-do-projeto} pela pasta do serviço que está configurando (ex: para configurar o backend, a pasta-do-projeto deve ser “backend”)


Agora criaremos um serviço no linux para a execução do script sh:

```
sudo nano /etc/systemd/system/rebuild-service.service
```

Preencha-o com o conteúdo:

```
[Unit]
Description=Inicializador de serviço
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/bin/bash /etc/project-shs/rebuild-service.sh
ExecStop=/usr/local/bin/docker-compose down
TimeoutStartSec=0

[Install]
WantedBy=multi-user.target

```

Agora basta executar o serviço criado:

```
sudo systemctl daemon-reload
sudo systemctl enable rebuild-service.service
sudo systemctl start rebuild-service.service
```

Dessa forma, os 4 serviços da solução, cada um em seu EC2, poderão ser atualizados de maneira mais fácil. Toda vez que for necessário atualizar o deploy, basta conectar-se ao EC2 por meio de SSH e executar o comando:

```
sudo service rebuild-service restart
```

Dessa maneira, o deploy dos serviços em EC2 estará pronto e o sistema estará disponível para o usuário.

Obs: O docker está configurado em todos os serviços para funcionar seguindo a porta 80. Dessa forma fica mais fácil a configuração dos grupos de segurança de todos os EC2. A única exceção é o RabbitMQ que seguindo o exemplo funcionará em portas diferentes. Para seguir o padrão, é possível configurar o docker para servir seu painel de ADM na porta 80 também.

O grupo realizou o deploy nos seguintes endereços de IP:

- IP API de transcrição -> 54.237.165.30
- IP API Backend -> 18.204.75.236	
- IP RabbitMQ -> 3.94.164.124
- IP API métricas -> 50.17.215.106
- Frontend -> 3.94.68.204


Os testes de produção foram realizados acessando os serviços individualmente e testando o fluxo completo uma vez. Além disso, para ter segurança dos processos das filas e monitorar as atividades de cada serviço, foi criado um dashboard no grafana:

![image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/0b18d28c-9cf5-4d8b-94a9-02125df1e655)


# Sprint 5

## Elaboração da Documentação Final do Projeto

### Funcionalidades Implementadas na Prova de Conceito

Nesta seção, fornecemos um resumo das funcionalidades-chave que foram implementadas na prova de conceito do nosso projeto. Estas funcionalidades foram escolhidas para demonstrar a viabilidade técnica e o valor potencial do projeto.

**Funcionalidade 1: Conexão à API de Vídeos e Conversão para .flac**

Esta funcionalidade permite a conexão à API de vídeos, o download dos vídeos armazenados e a conversão desses vídeos para o formato .flac. Isso é fundamental para a posterior transcrição dos áudios.

**Tecnologias Utilizadas:**

- API de Vídeos
- ffmpeg (fluent-ffmpeg)
- fs (File System)

<br>

**Implementação**

- Integração com API de Vídeos: Desenvolvemos um sistema de integração que permite acessar e baixar vídeos da API através do recebimento de uma URL.

- Conversão para .flac: Utilizamos a biblioteca ffmpeg de conversão para transformar os vídeos em arquivos .flac compatíveis com a transcrição de áudio.

- Armazenamento dos arquivos: Com o fs (File System) um módulo do Node.js para manipulação de arquivos no sistema de arquivos local, conseguimos realizar as manipulações necessarias para salvar o arquivo de áudio convertido

**Resultados**

- Os vídeos foram baixados com sucesso da API de Vídeos.
- A conversão para .flac foi realizada sem perda de qualidade.

<br>

**Funcionalidade 2: Transcrição de Áudios pela API da IBM**

Esta funcionalidade envolve a transcrição dos áudios dos vídeos, agora em formato .flac, utilizando a API da IBM. Isso permite a obtenção do texto correspondente aos áudios dos vídeos.

**Tecnologias Utilizadas**
- IBM Watson Speech to Text API

**Implementação**

- Envio para a API da IBM: Os arquivos .flac foram enviados para a API da IBM Watson Speech to Text para a transcrição dos áudios.

**Resultados**

-  As transcrições foram obtidas com leve perda de precisão pela API da IBM.
- O texto correspondente aos áudios dos vídeos foi obtido com sucesso.

<br> 

**Funcionalidade 3: Análise de Métricas por API Interna**

Esta funcionalidade envolve a análise das transcrições dos áudios, realizada por uma API interna desenvolvida por nós. A API retira métricas como nível do conteúdo formal, nível de uso de metáforas e interações com o ouvinte.

**Tecnologias Utilizadas**

- python;

**Implementação**

- Processamento das Transcrições: A API interna processa as transcrições dos áudios, identificando conteúdo formal, informal, metáforas e interações com o ouvinte.
- Geração de Métricas: Com base na análise das transcrições, a API gera métricas que são utilizadas na análise de conteúdo dos vídeos em uma escala de 0 a 10.

Observação: O cálculo para o retorno da métrica foi baseado em conclusões de discussões em grupo, e pode ser facilmente ajustado ao acessar a *formality_metric_api*.

**Resultados**

- Métricas como conteúdo formal, informal, metáforas e interações foram extraídas com sucesso das transcrições.
- As métricas geradas fornecem insights valiosos sobre o conteúdo dos vídeos.

<br>

**Funcionalidade 4: Geração de Gráficos Comparativos com Metadados dos Vídeos**

Esta funcionalidade envolve a geração de gráficos comparativos que combinam as métricas obtidas das transcrições dos áudios com os metadados dos vídeos, como a quantidade de views. Isso permite aos usuários identificar padrões de sucesso na plataforma.

**Tecnologias Utilizadas**

- React;
- Highcharts;
- Apexcharts

**Implementação**

- Combinação de Dados: As métricas das transcrições e os metadados dos vídeos foram combinados em nosso backend para a geração dos gráficos comparativos.
- Geração de Gráficos: Utilizamos ferramentas para criar gráficos que mostram as relações entre as métricas e os metadados, permitindo análises comparativas como *Highcharts* e *Apexcharts*.

**Resultados**

- Os gráficos comparativos foram gerados com sucesso, fornecendo insights visuais sobre os padrões de sucesso na plataforma.
- Os usuários podem facilmente identificar tendências e correlações entre as métricas e os metadados dos vídeos.

#### Benefícios do Projeto

O projeto proposto oferece uma solução inovadora para abordar as necessidades críticas e desafios enfrentados pelas plataformas e seus usuários, através de um assistente de análise de dados que utiliza tecnologias avançadas de processamento de linguagem natural (NLP) em vídeos, juntamente com a introdução de novas métricas de avaliação. Os principais benefícios desse projeto são:

1. Ganho de tempo: Ao automatizar a análise de dados em vídeos através do assistente de NLP, o projeto permite uma análise rápida e eficiente, economizando tempo precioso para os usuários e administradores das plataformas.

2. Eficiência: A utilização de tecnologias avançadas de processamento de linguagem natural aumenta a eficiência da análise de dados, permitindo uma compreensão mais rápida e precisa do conteúdo dos vídeos.

3. Melhor entrega de valor para os usuários: A personalização de conteúdo possibilitada pelo assistente de análise de dados ajuda as plataformas a entenderem melhor as preferências e interesses de seus usuários, permitindo uma entrega mais direcionada de conteúdo relevante, aumentando assim o engajamento e satisfação dos usuários.

4. Aumento dos ganhos a longo prazo: Ao melhorar a entrega de valor para os usuários e aumentar o engajamento, o projeto contribui para o aumento dos ganhos a longo prazo das plataformas, seja por meio de assinaturas, publicidade ou outras formas de monetização.

5. Facilidade e precisão: A utilização de novas métricas de avaliação e tecnologias avançadas garante uma análise mais precisa e detalhada do desempenho dos vídeos, proporcionando insights valiosos para otimizar estratégias de conteúdo e engajamento.

Em resumo, o projeto oferece uma abordagem revolucionária para compreender e engajar o público de forma mais eficaz, proporcionando ganhos significativos em termos de eficiência, personalização, retorno financeiro e qualidade na entrega de valor para os usuários e plataformas envolvidas.

### Revisão arquitetural

A solução proposta, em sua versão final, pode ser vista arquiteturalmente através de componentes e pacotes, que por sua vez representam agrupamentos de componentes por responsabilidade. Dessa forma, a seguir os pacotes e componentes que compõem o sistema:


![image](https://github.com/Inteli-College/2024-T0006-ES07-G02/assets/110608373/dcf47cb3-a19a-435f-9bea-c6c11db25b4d)


#### Pacote de Conexões Externas

Neste pacote estão contidos todos os componentes externos ao sistema desenvolvido, sendo vistos como serviços usados para fins específicos.

Vale ressaltar que cada componente desse pacote relaciona-se apenas com um componente do pacote de processamento, ou seja, as APIs da solução. Essa abordagem foi tomada devido ao conceito de encapsulamento que o grupo utilizou para evitar falhas de segurança devido as credenciais de acesso às APIs estarem em vários lugares diferentes e ao reaproveitamento de código, tornando serviços específicos desenvolvidos especialistas na comunicação com serviços externos determinados.


##### Componente IBM Speech To Text

**Descrição**:


Serviço de transcrição de áudio para texto utilizado. Seu provedor é a IBM e conta com uma gama de opções e usos diferentes que propicia novas funcionalidades posteriormente. Caso desejado, pode ser substituído por outro serviço de outros provedores.

**Relações**:


**API de Transcrição**: É o serviço consumido responsável pela transcrição de áudios. Comunicação através de uma API Restfull HTTP.

##### Componente API Samba Vídeos

**Descrição**:


A API Samba Vídeos é o principal componente externo sendo o contato com a matéria prima dessa solução: os vídeos. Através dela, o backend pode consumir informações sobre os vídeos além de seus arquivos brutos, usados para realizar as transcrições.

**Relações**:


**Backend**: Através do protocolo Rest, o backend realiza requisições HTTP para a API da Samba Vídeos a fim de, principalmente, consumir informações sobre os vídeos da plataforma.

##### Componente IBM NLU

**Descrição**:


O componente IBM NLU é uma API disponibilizada pela IBM que nos auxilia na identificação de sentimentos e intenções a partir de textos. É usada principalmente para a retirada de métricas.

**Relações**:


**API de processamento de Texto (métricas)**: Através de uma conexão Restfull pelo protocolo HTTP, A API de métricas utiliza esse serviço para obter intenções e sentimentos dos textos, assim, obtendo métricas do mesmo.

##### Componente GPT:

**Descrição**:


O componente GTP é utilizado para realizar análises em maior nível ou com um grau de complexidade maior, retirando assim, métricas mais analíticas do conteúdo dos vídeos.

**Relações**:


**API de processamento de Texto (métricas)**: Através de uma conexão Restfull pelo protocolo HTTP, A API de métricas utiliza esse serviço para realizar análises do conteúdo dos vídeos.

##### Processamento Interno

**Descrição**:


O componente de Processamento Interno é toda a operação de retirada de métricas criada internamente pela solução. Esse componente está no pacote de Conexões Externas devido a duas características:
Cada processamento específico pode estar em APIs diferentes, de acordo com a necessidade
Pode ser facilmente substituído por serviços externos.


**Relações**:


**API de processamento de Texto (métricas)**: Através de uma conexão Restfull pelo protocolo HTTP, A API de métricas utiliza esse serviço para realizar análises do conteúdo dos vídeos.

#### Pacote de Mensageria

O pacote de mensageria é responsável por lidar com a troca de mensagens do sistema. Na proposta de solução desse MVP, apenas filas foram utilizadas para a comunicação entre sistemas, porém, para o crescimento da solução, outras abordagens podem ser utilizadas dentro desse pacote e com suas interações.

#####  Componente RabbitMQ

**Descrição**:


RabbitMQ é um software livre de mensageria que foi utilizado pela solução principalmente pela facilidade de configurar e consumir filas. Utilizando uma metáfora, seria a coluna vertebral do sistema, ou seja, a forma como a informação sai de um componente central (backend) e chega até outros componentes. Sua implementação foi fundamental para assegurar o RNF3 - Processamento Paralelo de Transcrição e Retirada de Métricas.


**Relações**:


**Backend**: O principal produtor de mensagens no RabbitMQ é o backend. Através de rotinas e chamadas, produz mensagens pelo protocolo AQMP nas filas de ‘transcription’ e ‘get_metrics’ que por sua vez são consumidas pelos componentes especialistas.

**API de Transcrição**: Através do protocolo AQMP, consome mensagens da fila de ‘transcription’ para realizar seu processamento. A API de transcrição consumirá apenas 2 mensagens por vêz, o que permite lidar com vídeos maiores. Caso ocorra algum erro relacionado ao processo de conversão do vídeo para áudio ou comunicação com API de STT, a mensagem voltará para o final da fila para ser consumida posteriormente.

**API de processamento de Texto (métricas)**: Através do protocolo AQMP, consome mensagens da fila de ‘get_metrics’ para realizar seu processamento. A API de métricas consumirá 50 mensagens por vez, dessa forma poderá processar de forma mais rápida os vídeos, já que o tempo de processamento está atrelado ao tempo de resposta de APIs externas. Caso ocorra alguma exceção, a mensagem volta ao final da fila. Apenas vídeos que foram transcritos corretamente tem mensagens na fila de obter métricas.


#### Pacote de Processamento

O pacote de processamento é responsável por executar as regras de negócio da aplicação, ou seja, está conectado com os componentes externos, camada de persistência e mensageria. 

É importante destacar que os serviços presentes nesse pacote possuem tratamento de erros de forma a assegurar o RNF1 - Resistência a Erros.

#####  Componente Backend

**Descrição**:


O Backend é o coração da aplicação. Responsável pelas respostas das requisições feitas pelo usuário final através do frontend, criação de mensagens nas filas para processamento externo e compilação de resultados, é o principal componente da aplicação. Nele, também está contida a lógica do RF5 - Compilação de métricas dos vídeos.

**Relações**:


**RabbitMQ**: Através do protocolo AQMP, produz mensagens nas filas ‘transcription’ e ‘get_metrics’.

**API de Transcrição**: Através de um webhook, recebe o resultado de transcrições pelo protocolo HTTP.

**API de processamento de Texto (métricas)**: Através de um webhook, recebe o resultado de métricas pelo protocolo HTTP.

**API Samba Vídeos**: Através de requisições HTTP, consome informações de vídeos da API Samba Vídeos. Com essa integração, realizamos o RF1 - Obter vídeos do usuário.

**S3**: Sistema de Bucket usado para guardar metadados gerados dos vídeos e compilações de métricas. Utiliza o protocolo padrão S3 através da SDK da AWS.

**Mysql**: Banco de dados que guarda as informações de acompanhamento das filas e vídeos processados com seus status

**Frontend**: Responde às requisições do frontend com os dados necessários para criar as visualizações.


#####  Componente API de Transcrição

**Descrição**:


A API de Transcrição é o componente especialista em realizar transcrições. Toda a regra de negócio necessária para realizar as transcrições está nele, inclusive, a conversão de vídeo para áudio e comunicação com sistemas externos de transcrição, de acordo com o  RF2 - Gerar transcrição de vídeos da Samba Vídeos.


**Relações**:

**RabbitMQ**: Através do protocolo AQMP, consome mensagens na fila ‘transcription’.

**Backend**: Através de um webhook, envia o resultado de transcrições pelo protocolo HTTP.

**IBM Speech to Text**: Através de requisições HTTP, envia audio dos vídeos em processamento e recebe sua transcrição.

#####  Componente API de Processamento de Texto (métricas)

**Descrição**:


A API de Processamento de Texto (métricas) é o componente especialista em obter as métricas dos vídeos através de suas transcrições. Toda a regra de negócio necessária para realizar a retirada de métricas está nele, inclusive, a comunicação com sistemas externos para tal, de acordo com o RF3 - Obter Métricas de comunicação dos vídeos e RF4 - Obter Tópicos ditos nos vídeos


**Relações**:

**RabbitMQ**: Através do protocolo AQMP, consome mensagens na fila ‘get_metrics.

**Backend**: Através de um webhook, envia o resultado de métricas pelo protocolo HTTP.

**IBM NLU**: Através de requisições HTTP, envia transcrições dos vídeos em processamento e recebe suas intenções e sentimentos.

**GPT**: Através de requisições HTTP, envia transcrições dos vídeos em processamento e recebe análises profundas.

**Processamento Interno**: Através de requisições HTTP ou chamada de funções, processa informações dos vídeos para gerar métricas.


#### Pacote de Persistência

O pacote de persistência é responsável por guardar as informações da solução. O uso de duas ferramentas para persistência de dados é uma abordagem escolhida para a implementação do RNF2 - Desempenho na persistência de dados de métricas, transcrição e compilação, aproveitando os benefícios de uso de cada uma.

#####  Componente S3

**Descrição**:


Através do serviço S3 da AWS, informações são guardadas em formato de arquivos, o que é útil para guardar os resultados de compilações e metadados dos vídeos.


**Relações**:


**Backend**: O Backend comunica-se com o serviço S3 através do protocolo padrão realizado pela SDK da AWS.

#####  Componente Mysql

**Descrição**:


O Mysql é o banco de dados da aplicação e é responsável por guardar quais vídeos o sistema conhece e qual seus status de processamento, além de informações das filas.


**Relações**:


**Backend**: O Backend comunica-se com o banco de dados Mysql para guardar informações.

#### Pacote de Apresentação

O pacote de apresentação é a camada do sistema que o usuário final tem acesso, ou seja, como as informações chegam até ele.

#####  Componente Frontend

**Descrição**:


O Frontend é a aplicação que o usuário final tem acesso. Nele, são mostradas as informações de compilação com as métricas retiradas dos vídeos.


**Relações**:


**Backend**: O Backend responde às solicitações HTTP do frontend e retorna as informações mostradas ao usuário.


### Revisão dos Requisitos

Os requisitos do sistema foram revistos de acordo com as atualiazações e conversas com o parceiro durante as iterações de sprints. Os requisitos podem ser [vistos aqui](/README.md#entendimento-da-arquitetura-do-sistema)




